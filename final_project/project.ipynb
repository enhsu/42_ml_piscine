{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from pathlib import Path\n",
    "import timeit\n",
    "import datetime\n",
    "\n",
    "from tensorflow.keras.models import model_from_json\n",
    "from scipy.io import wavfile\n",
    "from scipy import signal\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, MaxPooling2D, Dense, Input, Dropout, Flatten\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "train_path = './data'\n",
    "sample_rate = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class get_data:\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "        self.get_data()\n",
    "        self.get_speg()\n",
    "        self.split_data()\n",
    "        self.get_label()\n",
    "\n",
    "    def get_data(self):\n",
    "        data_dir = Path(self.path)\n",
    "        # next(os.walk(path))[2]\n",
    "        files = [(str(file), file.parts[-2]) for file in data_dir.glob(\"**/*.txt\") if file]\n",
    "        self.df = pd.DataFrame(files, columns=['path', 'state'])\n",
    "\n",
    "    def get_speg(self):\n",
    "        ret_arr = list()\n",
    "        for i in range(len(self.df['path'])):\n",
    "            file = pd.read_csv(self.df['path'][i], index_col=0)\n",
    "            \n",
    "            f_lst = list()\n",
    "            for ch in range(4):\n",
    "                _, _, speg = self.log_specgram(file['ch' + str(ch + 1)], sample_rate)\n",
    "                speg = speg.reshape(len(speg), len(speg[0]), 1)\n",
    "                f_lst.append(speg)\n",
    "            speg_4ch = np.concatenate((f_lst[0], f_lst[1], f_lst[2], f_lst[3]), axis=2)\n",
    "            ret_arr.append(speg_4ch)\n",
    "        self.df['speg'] = ret_arr\n",
    "    \n",
    "    def log_specgram(\n",
    "        self,\n",
    "        audio,\n",
    "        sample_rate,\n",
    "#         window_size=20,\n",
    "#         step_size=10,\n",
    "        eps=1e-10\n",
    "    ):\n",
    "#         nperseg = int(round(window_size * sample_rate / 1e3))\n",
    "#         noverlap = int(round(step_size * sample_rate / 1e3))\n",
    "        nperseg=15 #25 40\n",
    "        noverlap=7 #20 20\n",
    "        freqs, times, spec = signal.spectrogram(audio,\n",
    "                                        fs=sample_rate,\n",
    "                                        window='hann',\n",
    "                                        nperseg=nperseg,\n",
    "                                        noverlap=noverlap,\n",
    "                                        detrend=False)\n",
    "        return freqs, times, np.log(spec.T.astype(np.float32) + eps)\n",
    "        \n",
    "    def split_data(self):\n",
    "#         labelbinarizer = LabelBinarizer()\n",
    "        self.X = self.df.speg\n",
    "        self.y = self.df.state\n",
    "        self.ts_f, self.vs_f, self.ts_l, self.vs_l =\\\n",
    "        train_test_split(\n",
    "            self.X,\n",
    "            self.y,\n",
    "            test_size=0.3,\n",
    "            stratify=self.y\n",
    "        )\n",
    "        self.vs_f, self.test_f, self.vs_l, self.test_l =\\\n",
    "        train_test_split(\n",
    "            self.vs_f,\n",
    "            self.vs_l,\n",
    "            test_size=0.5,\n",
    "            stratify=self.vs_l\n",
    "        )\n",
    "    \n",
    "    def get_label(self):\n",
    "        self.ts_l = pd.get_dummies(self.ts_l)\n",
    "        self.vs_l = pd.get_dummies(self.vs_l)\n",
    "        self.test_l = pd.get_dummies(self.test_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need:\n",
    "#   init shape\n",
    "class create_model:\n",
    "    def __init__(self, shape):\n",
    "        self.shape = shape\n",
    "        \n",
    "        self.build_model()\n",
    "        self.compile_model()\n",
    "        \n",
    "    def build_model(self):\n",
    "        input_layer = Input(shape=self.shape)\n",
    "        \n",
    "        model = BatchNormalization()(input_layer)\n",
    "        \n",
    "        model = Conv2D(filters=8, kernel_size=(2, 2), padding='same', activation='relu')(model)\n",
    "        model = Conv2D(8, (2, 2), padding='same', activation='relu')(model)\n",
    "        model = MaxPooling2D((2, 2))(model)\n",
    "        model = Dropout(0.2)(model)\n",
    "        \n",
    "        model = Conv2D(16, (3, 3), padding='same', activation='relu')(model)\n",
    "        model = Conv2D(16, (3, 3), padding='same', activation='relu')(model)\n",
    "        model = MaxPooling2D((2, 2))(model)\n",
    "        model = Dropout(0.2)(model)\n",
    "        \n",
    "        model = Conv2D(32, (3, 3), padding='same', activation='relu')(model)\n",
    "        model = MaxPooling2D((2, 2))(model)\n",
    "        model = Dropout(0.2)(model)\n",
    "\n",
    "        model = Flatten()(model)\n",
    "        model = BatchNormalization()(Dense(128, kernel_regularizer=regularizers.l2(0.01), activation='relu')(model))\n",
    "        model = BatchNormalization()(Dense(128, kernel_regularizer=regularizers.l2(0.01), activation='relu')(model))\n",
    "        \n",
    "        model = Dense(2, activation='softmax')(model)\n",
    "\n",
    "        self.model = Model(inputs=input_layer, outputs=model)\n",
    "        \n",
    "    def compile_model(self):\n",
    "        my_opt = tf.optimizers.Adam(\n",
    "            learning_rate=0.001\n",
    "        )\n",
    "        self.model.compile(loss='binary_crossentropy', optimizer=my_opt, metrics=['accuracy'])\n",
    "    \n",
    "    def train(\n",
    "        self,\n",
    "        ts_f,\n",
    "        ts_l,\n",
    "        vs_f,\n",
    "        vs_l,\n",
    "        epochs=10,\n",
    "        batch_size=25,\n",
    "        has_tb=True,\n",
    "        tb_path='./tensorboard/default'\n",
    "    ):\n",
    "        self.ts_f = np.array([data for data in ts_f])\n",
    "#         print(self.ts_f.shape)\n",
    "        self.ts_l = ts_l\n",
    "        self.vs_f = np.array([data for data in vs_f])\n",
    "        self.vs_l = vs_l\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.has_tb = has_tb\n",
    "        self.tb_path = tb_path\n",
    "        \n",
    "        fit_arg = dict(\n",
    "            x=self.ts_f,\n",
    "            y=self.ts_l,\n",
    "            epochs=self.epochs,\n",
    "            batch_size=self.batch_size,\n",
    "            validation_data=(self.vs_f, self.vs_l)\n",
    "        )\n",
    "        if has_tb:\n",
    "            tensorboard = TensorBoard(log_dir=self.tb_path)\n",
    "            fit_arg['callbacks'] = [tensorboard]\n",
    "        self.model.fit(**fit_arg)\n",
    "        \n",
    "    def evaluate(\n",
    "        self,\n",
    "        ts_f,\n",
    "        ts_l\n",
    "    ):\n",
    "        self.ts_f = np.array([data for data in ts_f])\n",
    "        self.ts_l = ts_l\n",
    "        \n",
    "        self.score = self.model.evaluate(self.ts_f, self.ts_l, verbose=1)\n",
    "#         print(self.score)\n",
    "#         print(self.model.metrics_names)\n",
    "        print(\"%s: %.2f\" % (self.model.metrics_names[0], self.score[0]))\n",
    "        print(\"%s: %.2f\" % (self.model.metrics_names[1], self.score[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data(train_path)\n",
    "# data.df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(shape=data.ts_f[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 700 samples, validate on 150 samples\n",
      "Epoch 1/20\n",
      "700/700 [==============================] - 2s 2ms/sample - loss: 3.5019 - accuracy: 0.5214 - val_loss: 3.1785 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "700/700 [==============================] - 0s 678us/sample - loss: 3.0969 - accuracy: 0.5300 - val_loss: 2.8119 - val_accuracy: 0.5133\n",
      "Epoch 3/20\n",
      "700/700 [==============================] - 0s 703us/sample - loss: 2.8578 - accuracy: 0.5100 - val_loss: 2.6149 - val_accuracy: 0.6000\n",
      "Epoch 4/20\n",
      "700/700 [==============================] - 1s 800us/sample - loss: 2.6400 - accuracy: 0.5486 - val_loss: 2.4439 - val_accuracy: 0.6267\n",
      "Epoch 5/20\n",
      "700/700 [==============================] - 1s 789us/sample - loss: 2.4926 - accuracy: 0.5586 - val_loss: 2.2995 - val_accuracy: 0.6667\n",
      "Epoch 6/20\n",
      "700/700 [==============================] - 1s 740us/sample - loss: 2.3266 - accuracy: 0.5757 - val_loss: 2.1940 - val_accuracy: 0.6467\n",
      "Epoch 7/20\n",
      "700/700 [==============================] - 1s 742us/sample - loss: 2.1853 - accuracy: 0.5771 - val_loss: 2.0926 - val_accuracy: 0.6067\n",
      "Epoch 8/20\n",
      "700/700 [==============================] - 1s 730us/sample - loss: 2.0781 - accuracy: 0.6400 - val_loss: 1.9277 - val_accuracy: 0.7133\n",
      "Epoch 9/20\n",
      "700/700 [==============================] - 0s 706us/sample - loss: 1.9330 - accuracy: 0.6600 - val_loss: 1.9126 - val_accuracy: 0.5200\n",
      "Epoch 10/20\n",
      "700/700 [==============================] - 1s 805us/sample - loss: 1.7290 - accuracy: 0.7529 - val_loss: 1.7856 - val_accuracy: 0.5733\n",
      "Epoch 11/20\n",
      "700/700 [==============================] - 0s 693us/sample - loss: 1.6411 - accuracy: 0.7843 - val_loss: 1.5790 - val_accuracy: 0.7733\n",
      "Epoch 12/20\n",
      "700/700 [==============================] - 0s 659us/sample - loss: 1.4985 - accuracy: 0.8000 - val_loss: 1.4048 - val_accuracy: 0.9067\n",
      "Epoch 13/20\n",
      "700/700 [==============================] - 0s 663us/sample - loss: 1.3575 - accuracy: 0.8629 - val_loss: 1.3958 - val_accuracy: 0.8533\n",
      "Epoch 14/20\n",
      "700/700 [==============================] - 1s 743us/sample - loss: 1.2522 - accuracy: 0.8629 - val_loss: 1.2042 - val_accuracy: 0.9400\n",
      "Epoch 15/20\n",
      "700/700 [==============================] - 1s 795us/sample - loss: 1.1552 - accuracy: 0.8957 - val_loss: 1.1170 - val_accuracy: 0.9200\n",
      "Epoch 16/20\n",
      "700/700 [==============================] - 0s 711us/sample - loss: 1.0586 - accuracy: 0.9171 - val_loss: 1.1075 - val_accuracy: 0.9067\n",
      "Epoch 17/20\n",
      "700/700 [==============================] - 1s 758us/sample - loss: 1.0094 - accuracy: 0.9186 - val_loss: 0.9456 - val_accuracy: 0.9533\n",
      "Epoch 18/20\n",
      "700/700 [==============================] - 1s 739us/sample - loss: 0.9305 - accuracy: 0.9257 - val_loss: 1.0426 - val_accuracy: 0.8933\n",
      "Epoch 19/20\n",
      "700/700 [==============================] - 0s 710us/sample - loss: 0.8801 - accuracy: 0.9300 - val_loss: 0.8092 - val_accuracy: 0.9600\n",
      "Epoch 20/20\n",
      "700/700 [==============================] - 1s 760us/sample - loss: 0.7993 - accuracy: 0.9529 - val_loss: 0.7670 - val_accuracy: 0.9600\n"
     ]
    }
   ],
   "source": [
    "model.train(data.ts_f, data.ts_l, data.vs_f, data.vs_l, epochs=20, has_tb=True, tb_path='./tensorboard/baseline_v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 202us/sample - loss: 0.7456 - accuracy: 0.9867\n",
      "loss: 0.75\n",
      "accuracy: 0.99\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(data.test_f, data.test_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST AREA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(199, 3, 4)\n"
     ]
    }
   ],
   "source": [
    "train = get_data(train_path)\n",
    "t_file = pd.read_csv(train.df['path'][0], index_col=0)\n",
    "t_file.head()\n",
    "\n",
    "t_ret = list()\n",
    "for ch in range(4):\n",
    "    _, _, speg = log_specgram(t_file['ch' + str(ch + 1)], sample_rate,) #window_size=50, step_size=35)\n",
    "    speg = speg.reshape(len(speg), len(speg[0]), 1)\n",
    "    t_ret.append(speg)\n",
    "    \n",
    "t = np.concatenate((t_ret[0], t_ret[1], t_ret[2], t_ret[3]), axis=2)\n",
    "print(t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 5\n",
      "(56, 8)\n"
     ]
    }
   ],
   "source": [
    "def t_log_specgram(audio, sample_rate, window_size=20,\n",
    "                 step_size=10, eps=1e-10):\n",
    "    nperseg = int(round(window_size * sample_rate / 1e3))\n",
    "    noverlap = int(round(step_size * sample_rate / 1e3))\n",
    "    print(nperseg, noverlap)\n",
    "    freqs, times, spec = signal.spectrogram(audio,\n",
    "                                    fs=sample_rate,\n",
    "                                    window='hann',\n",
    "                                    nperseg=14,\n",
    "                                    noverlap=7,\n",
    "                                    detrend=False)\n",
    "    return freqs, times, np.log(spec.T.astype(np.float32) + eps)\n",
    "\n",
    "t_file = pd.read_csv(train.df['path'][0], index_col=0)\n",
    "_, _, t_speg = t_log_specgram(t_file['ch1'], sample_rate, window_size=30, step_size=25)\n",
    "print(t_speg.shape)\n",
    "# print(t_speg)\n",
    "# print(1e3)\n",
    "# _, _, speg = log_specgram(train.df['path'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(131, 6)\n",
      "-5.2645254\n",
      "-5.430552\n",
      "-5.951558\n",
      "-5.430552\n",
      "(131, 6, 1)\n",
      "[[[ -5.2645254   -5.430552    -5.951558    -5.430552  ]\n",
      "  [ -3.627599    -1.7014384   -3.5742292   -1.7014384 ]\n",
      "  [ -2.8383954   -1.1714436   -2.3975449   -1.1714436 ]\n",
      "  [ -2.670378    -2.4234064   -2.0491207   -2.4234064 ]\n",
      "  [ -6.7914553   -5.824142    -6.251271    -5.824142  ]\n",
      "  [ -5.7685757   -6.5883374   -6.0156307   -6.5883374 ]]\n",
      "\n",
      " [[ -1.7589514   -5.4641457   -2.8844445   -5.4641457 ]\n",
      "  [ -0.8550425   -1.5390472   -2.9510193   -1.5390472 ]\n",
      "  [ -0.910285    -1.4026263   -2.3193738   -1.4026263 ]\n",
      "  [ -1.9432485   -2.9584148   -2.4692895   -2.9584148 ]\n",
      "  [ -3.945669    -7.3207483   -4.3558655   -7.3207483 ]\n",
      "  [ -6.797452   -10.346286    -8.22204    -10.346286  ]]\n",
      "\n",
      " [[ -1.5686886   -0.7950065   -2.900094    -0.7950065 ]\n",
      "  [ -1.9682143   -1.0798578   -2.2139988   -1.0798578 ]\n",
      "  [ -1.8498638   -3.7858036   -2.0329413   -3.7858036 ]\n",
      "  [ -3.023065    -3.234389    -3.8842907   -3.234389  ]\n",
      "  [ -4.5496087   -6.3293905   -4.856876    -6.3293905 ]\n",
      "  [ -5.478097    -8.3522625   -6.1887293   -8.3522625 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ -2.1793332   -0.3929926   -0.580735    -0.3929926 ]\n",
      "  [ -1.369778    -0.48328486   0.07328057  -0.48328486]\n",
      "  [ -1.150969    -3.8575308   -0.15706107  -3.8575308 ]\n",
      "  [ -2.2064595   -8.154516    -1.6874086   -8.154516  ]\n",
      "  [ -4.8668833   -4.690624    -4.8176155   -4.690624  ]\n",
      "  [ -8.218056   -14.414915   -14.631584   -14.414915  ]]\n",
      "\n",
      " [[ -1.7878356   -1.1819801   -3.5005207   -1.1819801 ]\n",
      "  [ -0.07214502  -0.8891208   -0.7655004   -0.8891208 ]\n",
      "  [ -0.7579355   -2.7227485   -0.6143701   -2.7227485 ]\n",
      "  [ -3.771988    -3.5120704   -2.438465    -3.5120704 ]\n",
      "  [ -6.0685415   -4.369362    -5.879004    -4.369362  ]\n",
      "  [ -6.044221    -8.917714    -7.5673795   -8.917714  ]]\n",
      "\n",
      " [[ -0.5892091   -1.90149     -3.8718705   -1.90149   ]\n",
      "  [ -0.866268    -0.8151395   -3.4634843   -0.8151395 ]\n",
      "  [ -1.832212    -2.4944625   -2.8890147   -2.4944625 ]\n",
      "  [ -7.5077167   -3.1690333   -3.0736327   -3.1690333 ]\n",
      "  [ -4.7114697   -4.1944456   -3.43006     -4.1944456 ]\n",
      "  [ -8.119131   -10.675836    -8.182833   -10.675836  ]]]\n"
     ]
    }
   ],
   "source": [
    "def log_specgram(audio, sample_rate, window_size=20,\n",
    "                 step_size=10, eps=1e-10):\n",
    "    nperseg = int(round(window_size * sample_rate / 1e3))\n",
    "    noverlap = int(round(step_size * sample_rate / 1e3))\n",
    "    freqs, times, spec = signal.spectrogram(audio,\n",
    "                                    fs=sample_rate,\n",
    "                                    window='hann',\n",
    "#                                     nperseg=nperseg,\n",
    "#                                     noverlap=noverlap,\n",
    "                                    nperseg=14,\n",
    "                                    noverlap=7,\n",
    "                                    detrend=False)\n",
    "    return freqs, times, np.log(spec.T.astype(np.float32) + eps)\n",
    "\n",
    "freqs1, times1, spectrogram1 = log_specgram(t_file['ch1'], sample_rate, window_size=50, step_size=35)\n",
    "freqs2, times2, spectrogram2 = log_specgram(t_file['ch2'], sample_rate, window_size=50, step_size=35)\n",
    "freqs3, times3, spectrogram3 = log_specgram(t_file['ch3'], sample_rate, window_size=50, step_size=35)\n",
    "freqs4, times4, spectrogram4 = log_specgram(t_file['ch2'], sample_rate, window_size=50, step_size=35)\n",
    "\n",
    "print(spectrogram1.shape)\n",
    "print(spectrogram1[0][0])\n",
    "print(spectrogram2[0][0])\n",
    "print(spectrogram3[0][0])\n",
    "print(spectrogram4[0][0])\n",
    "\n",
    "ta1 = spectrogram1.reshape(len(spectrogram1), len(spectrogram1[0]), 1)\n",
    "print(ta1.shape)\n",
    "ta2 = spectrogram2.reshape(len(spectrogram2), len(spectrogram2[0]), 1)\n",
    "ta3 = spectrogram3.reshape(len(spectrogram3), len(spectrogram3[0]), 1)\n",
    "ta4 = spectrogram4.reshape(len(spectrogram4), len(spectrogram4[0]), 1)\n",
    "# ta = np.append(ta1, ta2, axis=2)\n",
    "# ta = np.append(ta, ta3, axis=2)\n",
    "# ta = np.append(ta, ta4, axis=2)\n",
    "ta = np.concatenate((ta1, ta2, ta3, ta4), axis=2)\n",
    "print(ta)\n",
    "\n",
    "# speg = np.concatenate((spectrogram1, spectrogram2, spectrogram3, spectrogram4), axis=0)\n",
    "\n",
    "# print(speg)\n",
    "# print(speg.shape)\n",
    "\n",
    "# speg_4ch = []\n",
    "# for i in range(len(spectrogram1)):\n",
    "#     i_lst = list()\n",
    "#     for j in range(len(spectrogram1[0])):\n",
    "#         j_lst = list()\n",
    "#     speg_4ch.append(list())\n",
    "\n",
    "#     for j in range(len(spectrogram1[0])):\n",
    "#         print(spectrogram1[i][j])\n",
    "\n",
    "# print(len(speg_4ch))\n",
    "\n",
    "# print(\"freqs:\\n\", freqs, \"\\n\")\n",
    "# print(freqs.shape)\n",
    "# print(\"times:\\n\", times, \"\\n\")\n",
    "# print(times.shape)\n",
    "# print(\"spectrogram:\\n\", spectrogram4, \"\\n\")\n",
    "# print(spectrogram4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3 4 5 6]\n",
      " [1 2 3 4 5 6]]\n",
      "(1, 2, 3)\n"
     ]
    }
   ],
   "source": [
    "a = [[1, 2, 3], [1, 2, 3]]\n",
    "b = [[4, 5, 6], [4, 5, 6]]\n",
    "c = [[7, 8, 9], [7, 8, 9]]\n",
    "a = np.array(a)\n",
    "b = np.array(b)\n",
    "c = np.array(c)\n",
    "d = np.append(a, b, axis=1)\n",
    "print(d)\n",
    "# print(a.shape)\n",
    "# print(np.concatenate((a, b, c), axis=0))\n",
    "ta = []\n",
    "for i in range(300):\n",
    "    ta.append(i);\n",
    "# print(ta)\n",
    "ta = np.array(ta)\n",
    "ta = ta.reshape(10, 10, 3)\n",
    "# print(ta)\n",
    "# print(len(ta))\n",
    "# print(ta[0])\n",
    "taa = [[[1, 2, 3], [4, 5, 6]]]\n",
    "taa = np.array(taa)\n",
    "print(taa.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
