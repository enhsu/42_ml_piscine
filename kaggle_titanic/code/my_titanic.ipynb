{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models to make today:\n",
    "# model using only gender\n",
    "# model using gender + class\n",
    "# model using gender + class + age (binning)\n",
    "# model using gender + class + age + name (synthetic feature)  (optional)\n",
    "# make sure to attach tensorboard and screenshot training curve\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import metrics\n",
    "from tensorflow.python.data import Dataset\n",
    "\n",
    "from IPython import display\n",
    "\n",
    "# for sex_to_int() function\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# make TensorFlow less verbose\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file():\n",
    "    train_df = pd.read_csv(\"../input/train.csv\")\n",
    "    test_df = pd.read_csv(\"../input/test.csv\")\n",
    "    return train_df, test_df\n",
    "\n",
    "def drop_unused_cols(data_df):\n",
    "    UNUSED_COLUMNS = [\"Ticket\", \"Cabin\", \"Embarked\", \"Fare\", \"SibSp\", \"Parch\", 'PassengerId']\n",
    "    data_df = data_df.drop(UNUSED_COLUMNS, axis=1)\n",
    "    return data_df\n",
    "\n",
    "def fill_nan(data_df):\n",
    "#     train_df.Age.fillna((train_df.Age.mean()), inplace=True)\n",
    "    data_df.Age.fillna((data_df.Age.mean()), inplace=True)\n",
    "    return data_df\n",
    "\n",
    "def sex_to_int(data):\n",
    "    le = LabelEncoder()\n",
    "    le.fit([\"male\",\"female\"])\n",
    "    data[\"Sex\"]=le.transform(data[\"Sex\"]) \n",
    "    return data\n",
    "\n",
    "def pclass_col(data):\n",
    "    columns = [\"Pclass\"]\n",
    "    for column in columns:\n",
    "        data = pd.concat([data, pd.get_dummies(data[column], prefix=column)], axis=1)\n",
    "        data = data.drop(column, axis=1)\n",
    "    return data\n",
    "\n",
    "def feature_eng(data_df):\n",
    "    data_df = drop_unused_cols(data_df)\n",
    "    data_df = fill_nan(data_df)\n",
    "    data_df = sex_to_int(data_df)\n",
    "    data_df = pclass_col(data_df)\n",
    "    return data_df\n",
    "\n",
    "# # bin Age\n",
    "# def bin_age(dataframe, age_list):\n",
    "#     dataframe['Age'] = pd.cut(dataframe['Age'], age_list)\n",
    "#     return dataframe\n",
    "# ages = [0, 20, 40, 60, 100]\n",
    "# train_df = bin_age(train_df, ages)\n",
    "# test_df = bin_age(test_df, ages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_df(data_df):\n",
    "    # sample 80% for train data\n",
    "    train_set = data_df.sample(frac=0.8, replace=False, random_state=42)\n",
    "    # the other 20% is reserved for cross validation\n",
    "    cv_set = data_df.loc[ set(data_df.index) - set(train_set.index)]\n",
    "    return train_set, cv_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_quantile_based_boundaries(feature_values, num_buckets):\n",
    "    boundaries = np.arange(1.0, num_buckets) / num_buckets\n",
    "    quantiles = feature_values.quantile(boundaries)\n",
    "    return [quantiles[q] for q in quantiles.keys()]\n",
    "\n",
    "def construct_feature_columns(input_features, bin_age=False):\n",
    "    tmp_feature = [tf.feature_column.numeric_column(my_feature) for my_feature in input_features]\n",
    "    if bin_age:\n",
    "        tmp_age = tf.feature_column.numeric_column(\"Age\")\n",
    "        bucketized_age = tf.feature_column.bucketized_column(\n",
    "          tmp_age, boundaries=get_quantile_based_boundaries(\n",
    "            input_features[\"Age\"], 4))\n",
    "        tmp_feature += [bucketized_age]\n",
    "    return (set(tmp_feature))\n",
    "\n",
    "\n",
    "def my_input_fn(features, targets, batch_size=1, shuffle=True, num_epochs=None):\n",
    "    # Convert pandas data into a dict of np arrays.\n",
    "    features = {key:np.array(value) for key,value in dict(features).items()}                                           \n",
    " \n",
    "    # Construct a dataset, and configure batching/repeating.\n",
    "    ds = Dataset.from_tensor_slices((features,targets)) # warning: 2GB limit\n",
    "    ds = ds.batch(batch_size).repeat(num_epochs)\n",
    "    \n",
    "    # Shuffle the data, if specified.\n",
    "    if shuffle:\n",
    "      ds = ds.shuffle(10000)\n",
    "    \n",
    "    # Return the next batch of data.\n",
    "    features, labels = ds.make_one_shot_iterator().get_next()\n",
    "    return features, labels\n",
    "\n",
    "def create_optimizer(learning_rate):\n",
    "    my_optimizer = tf.train.FtrlOptimizer(learning_rate=learning_rate)\n",
    "    optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)\n",
    "    return optimizer\n",
    "\n",
    "def create_linear_regressor(feature_columns, optimizer, model_dir):\n",
    "    linear_regressor = tf.estimator.LinearRegressor(\n",
    "        feature_columns=feature_columns,\n",
    "        optimizer=optimizer,\n",
    "        model_dir = model_dir\n",
    "    )\n",
    "    return linear_regressor\n",
    "\n",
    "\n",
    "# feature_columns only use in create_linear_regressor, change the feature column -> feature will change\n",
    "# training data do not have to change, still can build the new model by changing the feature column\n",
    "def train_model(\n",
    "    learning_rate,\n",
    "    steps,\n",
    "    batch_size,\n",
    "    periods,\n",
    "    training_examples,\n",
    "    training_targets,\n",
    "    validation_examples,\n",
    "    validation_targets,\n",
    "    bin_age,\n",
    "    model_dir):\n",
    "    \n",
    "    steps_per_period = steps / periods\n",
    "    \n",
    "    feature_columns = construct_feature_columns(training_examples.copy(), bin_age)\n",
    "    optimizer = create_optimizer(learning_rate)\n",
    "    train_dir = model_dir + '/validation'\n",
    "#     print(train_dir)\n",
    "    linear_regressor = create_linear_regressor(feature_columns, optimizer, train_dir)\n",
    "    \n",
    "    vali_dir = model_dir + '/train'\n",
    "    linear_vali_regressor = create_linear_regressor(feature_columns, optimizer, vali_dir)\n",
    "    \n",
    "    training_input_fn = lambda: my_input_fn(training_examples, \n",
    "                                          training_targets[\"Survived\"], \n",
    "                                          batch_size=batch_size)\n",
    "    \n",
    "    training_vali_input_fn = lambda: my_input_fn(validation_examples, \n",
    "                                          validation_targets[\"Survived\"], \n",
    "                                          batch_size=batch_size)\n",
    "    \n",
    "    predict_training_input_fn = lambda: my_input_fn(training_examples, \n",
    "                                                  training_targets[\"Survived\"], \n",
    "                                                  num_epochs=1, \n",
    "                                                  shuffle=False)\n",
    "    p_v_input_fn = lambda: my_input_fn(validation_examples, \n",
    "                                          validation_targets[\"Survived\"], \n",
    "                                          num_epochs=1, \n",
    "                                          shuffle=False)\n",
    "    predict_validation_input_fn = lambda: my_input_fn(validation_examples, \n",
    "                                                    validation_targets[\"Survived\"], \n",
    "                                                    num_epochs=1, \n",
    "                                                    shuffle=False)\n",
    "    \n",
    "    \n",
    "#     training_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
    "#         x=train_set.drop('Survived', axis=1),\n",
    "#         y=train_set.Survived,\n",
    "#         num_epochs=None, # for training, use as many epochs as necessary\n",
    "#         shuffle=True,\n",
    "#         target_column='target',\n",
    "#         batch_size=batch_size\n",
    "#     )\n",
    "#     predict_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
    "#         x=cv_set.drop('Survived', axis=1),\n",
    "#         y=cv_set.Survived,\n",
    "#         num_epochs=1, # only to score\n",
    "#         shuffle=False,\n",
    "#         batch_size=batch_size\n",
    "#     )\n",
    "# #     predict_validation_input_fn\n",
    "    \n",
    "    \n",
    "    print(\"Training model...\")\n",
    "    print(\"RMSE (on training data):\")\n",
    "    training_rmse = []\n",
    "    validation_rmse = []\n",
    "    \n",
    "    for period in range (0, periods):\n",
    "        # Train the model, starting from the prior state.\n",
    "        linear_regressor.train(\n",
    "            input_fn=training_input_fn,\n",
    "            steps=steps_per_period\n",
    "        )\n",
    "        linear_vali_regressor.train(\n",
    "            input_fn=training_vali_input_fn,\n",
    "            steps=steps_per_period\n",
    "        )\n",
    "        \n",
    "        # Take a break and compute predictions.\n",
    "        training_predictions = linear_regressor.predict(input_fn=predict_training_input_fn)\n",
    "        training_predictions = np.array([item['predictions'][0] for item in training_predictions])\n",
    "        \n",
    "        v_ps = linear_vali_regressor.predict(input_fn=p_v_input_fn)\n",
    "        v_ps = np.array([item['predictions'][0] for item in v_ps])\n",
    "        \n",
    "#         validation_predictions = linear_regressor.predict(input_fn=predict_validation_input_fn)\n",
    "#         validation_predictions = np.array([item['predictions'][0] for item in validation_predictions])\n",
    "#         validation_eval = linear_regressor.evaluate(input_fn=predict_validation_input_fn)\n",
    "#         print(\"validation_eval: {}\".format(validation_eval['average_loss']))\n",
    "\n",
    "        # Compute training and validation loss.\n",
    "        training_root_mean_squared_error = math.sqrt(\n",
    "            metrics.mean_squared_error(training_predictions, training_targets))\n",
    "        \n",
    "#         validation_root_mean_squared_error = math.sqrt(\n",
    "#             metrics.mean_squared_error(validation_predictions, validation_targets))\n",
    "        \n",
    "        \n",
    "        # Occasionally print the current loss.\n",
    "        print(\"  period %02d : %0.2f\" % (period, training_root_mean_squared_error))\n",
    "        # Add the loss metrics from this period to our list.\n",
    "        training_rmse.append(training_root_mean_squared_error)\n",
    "#         validation_rmse.append(validation_root_mean_squared_error)\n",
    "    print(\"Model training finished.\")\n",
    "    # Output a graph of loss metrics over periods.\n",
    "#     plt.ylabel(\"RMSE\")\n",
    "#     plt.xlabel(\"Periods\")\n",
    "#     plt.title(\"Root Mean Squared Error vs. Periods\")\n",
    "#     plt.tight_layout()\n",
    "#     plt.plot(training_rmse, label=\"training\")\n",
    "#     plt.plot(validation_rmse, label=\"validation\")\n",
    "#     plt.legend()\n",
    "\n",
    "    return linear_regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_features(data_df):\n",
    "    processed_features = data_df.copy().drop('Survived', axis=1)\n",
    "    return processed_features\n",
    "\n",
    "def preprocess_targets(data_df):\n",
    "    output_targets = pd.DataFrame()\n",
    "    # Scale the target to be in units of thousands of dollars.\n",
    "    output_targets[\"Survived\"] = data_df[\"Survived\"]\n",
    "    return output_targets\n",
    "\n",
    "def get_examples_targets(data_df):\n",
    "    data_examples = preprocess_features(data_df)\n",
    "    data_targets = preprocess_targets(data_df)\n",
    "    return data_examples, data_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model(\n",
    "    learning_rate,\n",
    "    steps,\n",
    "    batch_size,\n",
    "    periods,\n",
    "    train_df,\n",
    "    model_dir,\n",
    "    bin_age=False):\n",
    "    \n",
    "#     learning_rate=0.2,\n",
    "#     steps=500,\n",
    "#     batch_size=100,\n",
    "#     period=10,\n",
    "\n",
    "#     train_df = get_file()\n",
    "#     train_df = feature_eng(train_df)\n",
    "\n",
    "#     test_df = feature_eng(test_df)\n",
    "    train_set, cv_set = split_train_df(train_df)\n",
    "    training_examples, training_targets = get_examples_targets(train_df)\n",
    "    validation_examples, validation_targets = get_examples_targets(cv_set)\n",
    "    linear_regressor = train_model(\n",
    "        learning_rate=learning_rate,\n",
    "        steps=steps,\n",
    "        batch_size=batch_size,\n",
    "        periods=periods,\n",
    "#         feature_columns=construct_feature_columns(training_examples)\n",
    "        training_examples=training_examples,\n",
    "        training_targets=training_targets,\n",
    "        validation_examples=validation_examples,\n",
    "        validation_targets=validation_targets,\n",
    "        bin_age=bin_age,\n",
    "        model_dir=model_dir\n",
    "    )\n",
    "    return (linear_regressor)\n",
    "    \n",
    "# init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = get_file()\n",
    "final_data = pd.read_csv(\"../input/gender_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "RMSE (on training data):\n",
      "  period 00 : 0.55\n",
      "  period 01 : 0.54\n",
      "  period 02 : 0.52\n",
      "  period 03 : 0.52\n",
      "  period 04 : 0.51\n",
      "  period 05 : 0.50\n",
      "  period 06 : 0.50\n",
      "  period 07 : 0.49\n",
      "  period 08 : 0.49\n",
      "  period 09 : 0.49\n",
      "Model training finished.\n"
     ]
    }
   ],
   "source": [
    "# model 1, only gender\n",
    "def get_sex_df(data_df):\n",
    "    ret_df = data_df.copy()\n",
    "    ret_df = feature_eng(ret_df)[['Survived', 'Sex']]\n",
    "    return ret_df\n",
    "\n",
    "def get_t_sex_df(data_df):\n",
    "    ret_df = data_df.copy()\n",
    "    ret_df = feature_eng(ret_df)[['Sex']]\n",
    "    return ret_df\n",
    "\n",
    "train_sex_df = get_sex_df(train_df)\n",
    "test_sex_df = get_t_sex_df(test_df)\n",
    "model_gender = init_model(\n",
    "    learning_rate = 0.008,\n",
    "    batch_size = 8,\n",
    "    steps = 800,\n",
    "    periods = 10,\n",
    "    train_df = train_sex_df,\n",
    "    model_dir = './tensorboard/train_vali_loss/model1_v6'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "RMSE (on training data):\n",
      "  period 00 : 0.48\n",
      "  period 01 : 0.46\n",
      "  period 02 : 0.44\n",
      "  period 03 : 0.43\n",
      "  period 04 : 0.42\n",
      "  period 05 : 0.42\n",
      "  period 06 : 0.41\n",
      "  period 07 : 0.41\n",
      "  period 08 : 0.41\n",
      "  period 09 : 0.41\n",
      "  period 10 : 0.40\n",
      "  period 11 : 0.40\n",
      "  period 12 : 0.40\n",
      "  period 13 : 0.40\n",
      "  period 14 : 0.40\n",
      "Model training finished.\n"
     ]
    }
   ],
   "source": [
    "# model 2, gender & class\n",
    "def get_gender_class_df(data_df):\n",
    "    ret_df = data_df.copy()\n",
    "    ret_df = feature_eng(ret_df)[['Survived', 'Sex', 'Pclass_1', 'Pclass_2', 'Pclass_3']]\n",
    "    return ret_df\n",
    "\n",
    "def get_t_gender_class_df(data_df):\n",
    "    ret_df = data_df.copy()\n",
    "    ret_df = feature_eng(ret_df)[['Sex', 'Pclass_1', 'Pclass_2', 'Pclass_3']]\n",
    "    return ret_df\n",
    "\n",
    "train_sex_class_df = get_gender_class_df(train_df)\n",
    "test_sex_class_df = get_t_gender_class_df(test_df)\n",
    "model_gender_class = init_model(\n",
    "    learning_rate = 0.02,\n",
    "    batch_size = 5,\n",
    "    steps = 1000,\n",
    "    periods = 15,\n",
    "    train_df = train_sex_class_df,\n",
    "    model_dir = './tensorboard/train_vali_loss/model2_v0'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "RMSE (on training data):\n",
      "  period 00 : 0.51\n",
      "  period 01 : 0.46\n",
      "  period 02 : 0.44\n",
      "  period 03 : 0.44\n",
      "  period 04 : 0.42\n",
      "  period 05 : 0.42\n",
      "  period 06 : 0.42\n",
      "  period 07 : 0.45\n",
      "  period 08 : 0.41\n",
      "  period 09 : 0.42\n",
      "  period 10 : 0.44\n",
      "  period 11 : 0.41\n",
      "  period 12 : 0.41\n",
      "  period 13 : 0.41\n",
      "  period 14 : 0.41\n",
      "Model training finished.\n"
     ]
    }
   ],
   "source": [
    "# model 3, gender & class & age\n",
    "def get_gender_class_age_df(data_df):\n",
    "    ret_df = data_df.copy()\n",
    "    ret_df = feature_eng(ret_df)[['Survived', 'Sex', 'Pclass_1', 'Pclass_2', 'Pclass_3', 'Age']]\n",
    "    return ret_df\n",
    "\n",
    "def get_t_gender_class_age_df(data_df):\n",
    "    ret_df = data_df.copy()\n",
    "    ret_df = feature_eng(ret_df)[['Sex', 'Pclass_1', 'Pclass_2', 'Pclass_3', 'Age']]\n",
    "    return ret_df\n",
    "\n",
    "train_sex_class_age_df = get_gender_class_age_df(train_df)\n",
    "test_sex_class_age_df = get_t_gender_class_age_df(test_df)\n",
    "model_gender_class_age = init_model(\n",
    "    learning_rate = 0.02,\n",
    "    batch_size = 5,\n",
    "    steps = 1000,\n",
    "    periods = 15,\n",
    "    train_df = train_sex_class_age_df,\n",
    "    model_dir = './tensorboard/train_vali_loss/model3_v0',\n",
    "    bin_age = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t_df = train_df.copy()\n",
    "# t_df = feature_eng(t_df)\n",
    "# t_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run test.csv prediction & generate csv file\n",
    "def predic_fn(x):\n",
    "    if x > 0.6:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def calculate_accuracy(model, model_input_fn):\n",
    "    predictions = list(model.predict(input_fn=model_input_fn))\n",
    "    predictions = np.array([item['predictions'][0] for item in predictions])\n",
    "    predictions = list(map(predic_fn, predictions))\n",
    "#     print(*predictions)\n",
    "#     print(final_data['Survived'])\n",
    "    \n",
    "    accuracy = pd.Series(predictions == final_data['Survived'])\n",
    "    accuracy = accuracy.sum() / accuracy.count()\n",
    "    return accuracy\n",
    "\n",
    "def create_test_input_fn(test_example):\n",
    "    test_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
    "          x=test_example,\n",
    "          num_epochs=1, # only to predict\n",
    "          shuffle=False \n",
    "    )\n",
    "    return test_input_fn\n",
    "\n",
    "m1_fn = create_test_input_fn(test_sex_df)\n",
    "m2_fn = create_test_input_fn(test_sex_class_df)\n",
    "m3_fn = create_test_input_fn(test_sex_class_age_df)\n",
    "\n",
    "predict1 = calculate_accuracy(model_gender, m1_fn)\n",
    "predict2 = calculate_accuracy(model_gender_class, m2_fn)\n",
    "predict3 = calculate_accuracy(model_gender_class_age, m3_fn)\n",
    "print(\"predict1 = {}\".format(predict1))\n",
    "print(\"predict2 = {}\".format(predict2))\n",
    "print(\"predict3 = {}\".format(predict3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8277511961722488\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>897</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>898</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>899</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>900</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>901</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>903</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>904</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>905</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>906</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>907</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>908</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>909</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>910</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>911</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>912</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>913</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>914</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>915</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>916</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>917</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>918</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>919</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>920</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>921</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>1280</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>1281</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>1282</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>1283</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>1284</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>1285</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>1286</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>1287</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>1288</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>1289</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>1290</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>1291</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>1292</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>1293</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>1294</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>1295</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>1296</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>1297</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>1298</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>1299</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>1300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>1301</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>1302</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>1303</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>1304</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived\n",
       "0            892         0\n",
       "1            893         0\n",
       "2            894         0\n",
       "3            895         0\n",
       "4            896         0\n",
       "5            897         0\n",
       "6            898         0\n",
       "7            899         0\n",
       "8            900         0\n",
       "9            901         0\n",
       "10           902         0\n",
       "11           903         0\n",
       "12           904         1\n",
       "13           905         0\n",
       "14           906         1\n",
       "15           907         1\n",
       "16           908         0\n",
       "17           909         0\n",
       "18           910         0\n",
       "19           911         0\n",
       "20           912         0\n",
       "21           913         0\n",
       "22           914         1\n",
       "23           915         0\n",
       "24           916         1\n",
       "25           917         0\n",
       "26           918         1\n",
       "27           919         0\n",
       "28           920         0\n",
       "29           921         0\n",
       "..           ...       ...\n",
       "388         1280         0\n",
       "389         1281         0\n",
       "390         1282         0\n",
       "391         1283         1\n",
       "392         1284         0\n",
       "393         1285         0\n",
       "394         1286         0\n",
       "395         1287         1\n",
       "396         1288         0\n",
       "397         1289         1\n",
       "398         1290         0\n",
       "399         1291         0\n",
       "400         1292         1\n",
       "401         1293         0\n",
       "402         1294         1\n",
       "403         1295         0\n",
       "404         1296         0\n",
       "405         1297         0\n",
       "406         1298         0\n",
       "407         1299         0\n",
       "408         1300         0\n",
       "409         1301         0\n",
       "410         1302         0\n",
       "411         1303         1\n",
       "412         1304         0\n",
       "413         1305         0\n",
       "414         1306         1\n",
       "415         1307         0\n",
       "416         1308         0\n",
       "417         1309         0\n",
       "\n",
       "[418 rows x 2 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = list(model_gender_class.predict(input_fn=m2_fn))\n",
    "predictions = np.array([item['predictions'][0] for item in predictions])\n",
    "predictions = list(map(predic_fn, predictions))\n",
    "\n",
    "final_accuracy = pd.Series(predictions == final_data['Survived'])\n",
    "final_accuracy = final_accuracy.sum() / final_accuracy.count()\n",
    "print(final_accuracy)\n",
    "\n",
    "evaluation = test_df['PassengerId'].copy().to_frame()\n",
    "evaluation[\"Survived\"] = predictions\n",
    "evaluation.to_csv(\"evaluation_submission.csv\", index=False)\n",
    "evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
