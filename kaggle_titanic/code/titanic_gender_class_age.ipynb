{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models to make today:\n",
    "# model using only gender\n",
    "# model using gender + class\n",
    "# model using gender + class + age (binning)\n",
    "# model using gender + class + age + name (synthetic feature)  (optional)\n",
    "# make sure to attach tensorboard and screenshot training curve\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import metrics\n",
    "from tensorflow.python.data import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from IPython import display\n",
    "\n",
    "# for sex_to_int() function\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# make TensorFlow less verbose\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "train_path = '../input/train.csv'\n",
    "test_path = '../input/test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class get_data:\n",
    "    def __init__(self, path, model_lst, is_train=True):\n",
    "        self.model_lst = model_lst\n",
    "        self.is_train = is_train\n",
    "        \n",
    "        self.feature = pd.read_csv(path)\n",
    "        \n",
    "        self.get_feature_label()\n",
    "        self.deal_feature()\n",
    "        \n",
    "        self.get_model()\n",
    "        self.split_t_v()\n",
    "        \n",
    "    def get_model(self):\n",
    "        self.feature = self.feature[self.model_lst]\n",
    "        self.get_dum()\n",
    "        self.fill_age()\n",
    "        \n",
    "    def fill_age(self):\n",
    "        self.feature['Age'].fillna((self.feature['Age'].mean()), inplace=True)\n",
    "        \n",
    "#     def get_dum(self):\n",
    "#         self.feature = pd.get_dummies(self.feature, dummy_na=True)\n",
    "    \n",
    "    def deal_feature(self):\n",
    "        self.sex_to_int()\n",
    "    \n",
    "    def feature_eng(self):\n",
    "        self.fill_nan()\n",
    "        self.drop_cols()\n",
    "        self.sex_to_int()\n",
    "    \n",
    "    def get_feature_label(self):\n",
    "        if self.is_train:\n",
    "            self.label = self.feature['Survived']\n",
    "            self.feature = self.feature.drop('Survived', axis=1)\n",
    "    \n",
    "#     def fill_nan(self):\n",
    "#         self.feature.fillna(0, inplace=True)\n",
    "    \n",
    "#     def drop_cols(self):\n",
    "#         UNUSED_COLUMNS = [\"Ticket\", \"Cabin\", \"Embarked\", \"Fare\", \"SibSp\", \"Parch\", 'PassengerId']\n",
    "#         self.feature = self.df.drop(UNUSED_COLUMNS, axis=1)\n",
    "        \n",
    "    def sex_to_int(self):\n",
    "        gender = {'male': 1, 'female': 0}\n",
    "        self.feature['Sex'] = [gender[item] for item in self.feature['Sex']]\n",
    "#         self.feature['Sex'][self.feature['Sex'] == 'male'] = 1\n",
    "#         self.feature['Sex'][self.feature['Sex'] == 'female'] = 0\n",
    "        \n",
    "    def get_dum(self):\n",
    "        columns = [\"Pclass\"]\n",
    "        for column in columns:\n",
    "            self.feature = pd.concat([self.feature, pd.get_dummies(self.feature[column], prefix=column)], axis=1)\n",
    "            self.feature = self.feature.drop(column, axis=1)\n",
    "            \n",
    "    def split_t_v(self):\n",
    "        self.ts_f, self.vs_f, self.ts_l, self.vs_l = \\\n",
    "        train_test_split(\n",
    "            self.feature,\n",
    "            self.label,\n",
    "            test_size=0.2,\n",
    "            random_state=42\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class create_model:\n",
    "    def __init__(\n",
    "        self,\n",
    "        feature,\n",
    "        learning_rate=0.3,\n",
    "        steps=10,\n",
    "        periods=30,\n",
    "        batch_size=100,\n",
    "        save_model=True,\n",
    "        load_model=False,\n",
    "        save_model_dir='./default_model',\n",
    "        load_model_dir='./default_model',\n",
    "        bin_age=False\n",
    "    ):\n",
    "        self.feature = feature\n",
    "        self.learning_rate = learning_rate\n",
    "        self.steps = steps\n",
    "        self.periods = periods\n",
    "        self.batch_size = batch_size\n",
    "        self.bin_age = bin_age\n",
    "        \n",
    "        self.save_model = save_model\n",
    "        self.save_model_dir = save_model_dir\n",
    "        self.load_model = load_model\n",
    "        self.load_model_dir = load_model_dir\n",
    "        \n",
    "        self.create_optimizer()\n",
    "        \n",
    "        # create model by dict\n",
    "        model_par = dict(\n",
    "            feature_columns = self.get_feature_cols(),\n",
    "            optimizer = self.optimizer,\n",
    "            n_classes = 2\n",
    "        )\n",
    "        if self.save_model:\n",
    "            model_par['model_dir'] = self.save_model_dir\n",
    "        if self.load_model:\n",
    "            model_par['warm_start_from'] = self.load_model_dir\n",
    "        self.model = tf.estimator.LinearClassifier(**model_par)\n",
    "        \n",
    "    \n",
    "#         self.model = tf.estimator.LinearRegressor(\n",
    "#             feature_columns = self.get_feature_cols(),\n",
    "#             optimizer = self.optimizer\n",
    "#         )\n",
    "        print('create model!')\n",
    "        \n",
    "    def get_feature_cols(self):\n",
    "        tmp_feature = [tf.feature_column.numeric_column(my_feature) for my_feature in self.feature]\n",
    "        if self.bin_age: # boolean:\n",
    "            tmp_age = tf.feature_column.numeric_column(\"Age\")\n",
    "            bucketized_age = tf.feature_column.bucketized_column(\n",
    "              tmp_age, boundaries=self.get_quantile_based_boundaries(\n",
    "                self.feature[\"Age\"], 4))\n",
    "            tmp_feature += [bucketized_age]\n",
    "        return set(tmp_feature)\n",
    "    \n",
    "    def get_quantile_based_boundaries(self, feature_values, num_buckets):\n",
    "        boundaries = np.arange(1.0, num_buckets) / num_buckets\n",
    "        quantiles = feature_values.quantile(boundaries)\n",
    "        return [quantiles[q] for q in quantiles.keys()]\n",
    "    \n",
    "    def create_optimizer(self):\n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate=self.learning_rate)\n",
    "        \n",
    "        '''\n",
    "        self.optimizer = tf.train.GradientDescentOptimizer(learning_rate=self.learning_rate)\n",
    "        self.optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_opt, 2.0)\n",
    "        '''\n",
    "    \n",
    "    def train(\n",
    "        self,\n",
    "        ts_f,\n",
    "        ts_l,\n",
    "        vs_f,\n",
    "        vs_l\n",
    "    ):\n",
    "        self.ts_f = ts_f\n",
    "        self.ts_l = ts_l\n",
    "        self.vs_f = vs_f\n",
    "        self.vs_l = vs_l\n",
    "        self.create_input_fn()\n",
    "        \n",
    "        steps_per_period = self.steps / self.periods\n",
    "        print('start training...')\n",
    "        for period in range(self.periods):\n",
    "#             print(\" period %02d start\" % (period))\n",
    "            train = self.model.train(\n",
    "                input_fn=self.train_input_fn,\n",
    "                steps=steps_per_period\n",
    "            )\n",
    "#             evaluate_train = self.model.evaluate(\n",
    "#                 input_fn=self.train_eval_fn\n",
    "#             )\n",
    "            evaluate_vali = self.model.evaluate(\n",
    "                input_fn=self.vali_eval_fn\n",
    "            )\n",
    "            \n",
    "#             print(train)\n",
    "#             print(evaluate_train)\n",
    "            print(evaluate_vali)\n",
    "            print('\\n')\n",
    "            \n",
    "#             print(\" period %02d finish\" % (period))\n",
    "        print(\"Model training finished.\")\n",
    "        \n",
    "    def create_input_fn(self):\n",
    "        self.train_input_fn = lambda: self.my_input_fn(self.ts_f, self.ts_l, batch_size=self.batch_size)\n",
    "        self.train_eval_fn = lambda: self.my_input_fn(self.ts_f, self.ts_l, shuffle=True, num_epochs=1)\n",
    "        self.vali_eval_fn = lambda: self.my_input_fn(self.vs_f, self.vs_l, shuffle=True, num_epochs=1)\n",
    "        \n",
    "    def my_input_fn(self, features, targets, batch_size=1, shuffle=True, num_epochs=None):\n",
    "        # Convert pandas data into a dict of np arrays.\n",
    "        features = {key:np.array(value) for key,value in dict(features).items()}\n",
    "        # Construct a dataset, and configure batching/repeating.\n",
    "        ds = Dataset.from_tensor_slices((features,targets)) # warning: 2GB limit\n",
    "        ds = ds.batch(batch_size).repeat(num_epochs)\n",
    "        # Shuffle the data, if specified.\n",
    "        if shuffle:\n",
    "            ds = ds.shuffle(42)\n",
    "        # Return the next batch of data.\n",
    "        features, labels = ds.make_one_shot_iterator().get_next()\n",
    "        return features, labels\n",
    "    \n",
    "    def predict(self, test_df):\n",
    "        print('predict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>1</td>\n",
       "      <td>45.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>1</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sex   Age  Pclass_1  Pclass_2  Pclass_3\n",
       "331    1  45.5         1         0         0\n",
       "733    1  23.0         0         1         0\n",
       "382    1  32.0         0         0         1\n",
       "704    1  26.0         0         0         1\n",
       "813    0   6.0         0         0         1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gender = ['Sex']\n",
    "model_gender_class = ['Sex', 'Pclass']\n",
    "model_gender_class_age = ['Sex', 'Pclass', 'Age']\n",
    "model_gender_class_age_name = ['Sex', 'Pclass', 'Age', 'Name']\n",
    "\n",
    "data = get_data(train_path, model_gender_class_age)\n",
    "# test = get_data(test_path)\n",
    "# data.get_model(model_gender)\n",
    "data.ts_f.head(5)\n",
    "# data.label.head(5)\n",
    "# print(data.feature['Sex'].isnull().count())\n",
    "# print(data.feature['Pclass'].isnull().any())\n",
    "# print(data.feature['Age'].isna().any())\n",
    "# print(data.feature['Name'].isnull().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create model!\n"
     ]
    }
   ],
   "source": [
    "model = create_model(\n",
    "    feature=data.feature,\n",
    "    learning_rate=0.08,\n",
    "#     save_model=False\n",
    "    save_model_dir='./model/gca_v0',\n",
    "    bin_age=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sex         712\n",
      "Age         712\n",
      "Pclass_1    712\n",
      "Pclass_2    712\n",
      "Pclass_3    712\n",
      "dtype: int64 \n",
      "\n",
      "shape (712, 5) \n",
      "\n",
      "712 \n",
      "\n",
      "shape (712,) \n",
      "\n",
      "Sex         179\n",
      "Age         179\n",
      "Pclass_1    179\n",
      "Pclass_2    179\n",
      "Pclass_3    179\n",
      "dtype: int64 \n",
      "\n",
      "shape (179, 5) \n",
      "\n",
      "179 \n",
      "\n",
      "shape (179,) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(data.ts_f.count(), '\\n')\n",
    "print('shape', data.ts_f.shape, '\\n')\n",
    "\n",
    "print(data.ts_l.count(), '\\n')\n",
    "print('shape', data.ts_l.shape, '\\n')\n",
    "\n",
    "print(data.vs_f.count(), '\\n')\n",
    "print('shape', data.vs_f.shape, '\\n')\n",
    "\n",
    "print(data.vs_l.count(), '\\n')\n",
    "print('shape', data.vs_l.shape, '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training...\n",
      "{'accuracy': 0.5865922, 'accuracy_baseline': 0.5865922, 'auc': 0.5816602, 'auc_precision_recall': 0.5321438, 'average_loss': 1.1112652, 'label/mean': 0.41340783, 'loss': 1.1112652, 'precision': 0.0, 'prediction/mean': 0.09568993, 'recall': 0.0, 'global_step': 1}\n",
      "\n",
      "\n",
      "{'accuracy': 0.59217876, 'accuracy_baseline': 0.5865922, 'auc': 0.58848137, 'auc_precision_recall': 0.54775363, 'average_loss': 0.6899393, 'label/mean': 0.41340783, 'loss': 0.6899393, 'precision': 1.0, 'prediction/mean': 0.29895636, 'recall': 0.013513514, 'global_step': 2}\n",
      "\n",
      "\n",
      "{'accuracy': 0.41340783, 'accuracy_baseline': 0.5865922, 'auc': 0.57142854, 'auc_precision_recall': 0.43924373, 'average_loss': 0.8633, 'label/mean': 0.41340783, 'loss': 0.8633, 'precision': 0.41340783, 'prediction/mean': 0.6974539, 'recall': 1.0, 'global_step': 3}\n",
      "\n",
      "\n",
      "{'accuracy': 0.41340783, 'accuracy_baseline': 0.5865922, 'auc': 0.51866156, 'auc_precision_recall': 0.40933955, 'average_loss': 1.3171228, 'label/mean': 0.41340783, 'loss': 1.3171228, 'precision': 0.41340783, 'prediction/mean': 0.8556545, 'recall': 1.0, 'global_step': 4}\n",
      "\n",
      "\n",
      "{'accuracy': 0.41340783, 'accuracy_baseline': 0.5865922, 'auc': 0.59555984, 'auc_precision_recall': 0.45676547, 'average_loss': 0.922198, 'label/mean': 0.41340783, 'loss': 0.922198, 'precision': 0.41340783, 'prediction/mean': 0.7359906, 'recall': 1.0, 'global_step': 5}\n",
      "\n",
      "\n",
      "{'accuracy': 0.6927374, 'accuracy_baseline': 0.5865922, 'auc': 0.78828824, 'auc_precision_recall': 0.76764727, 'average_loss': 0.6241829, 'label/mean': 0.41340783, 'loss': 0.6241829, 'precision': 0.88, 'prediction/mean': 0.43021175, 'recall': 0.2972973, 'global_step': 6}\n",
      "\n",
      "\n",
      "{'accuracy': 0.5865922, 'accuracy_baseline': 0.5865922, 'auc': 0.6738739, 'auc_precision_recall': 0.63624954, 'average_loss': 0.76388735, 'label/mean': 0.41340783, 'loss': 0.76388735, 'precision': 0.0, 'prediction/mean': 0.19031875, 'recall': 0.0, 'global_step': 7}\n",
      "\n",
      "\n",
      "{'accuracy': 0.5865922, 'accuracy_baseline': 0.5865922, 'auc': 0.64736164, 'auc_precision_recall': 0.602272, 'average_loss': 1.0773213, 'label/mean': 0.41340783, 'loss': 1.0773213, 'precision': 0.0, 'prediction/mean': 0.091512084, 'recall': 0.0, 'global_step': 8}\n",
      "\n",
      "\n",
      "{'accuracy': 0.5865922, 'accuracy_baseline': 0.5865922, 'auc': 0.64903474, 'auc_precision_recall': 0.6050756, 'average_loss': 1.1795534, 'label/mean': 0.41340783, 'loss': 1.1795534, 'precision': 0.0, 'prediction/mean': 0.07430323, 'recall': 0.0, 'global_step': 9}\n",
      "\n",
      "\n",
      "{'accuracy': 0.5865922, 'accuracy_baseline': 0.5865922, 'auc': 0.6664736, 'auc_precision_recall': 0.6262852, 'average_loss': 1.0845382, 'label/mean': 0.41340783, 'loss': 1.0845382, 'precision': 0.0, 'prediction/mean': 0.08657205, 'recall': 0.0, 'global_step': 10}\n",
      "\n",
      "\n",
      "{'accuracy': 0.5865922, 'accuracy_baseline': 0.5865922, 'auc': 0.712677, 'auc_precision_recall': 0.6821835, 'average_loss': 0.8636487, 'label/mean': 0.41340783, 'loss': 0.8636487, 'precision': 0.0, 'prediction/mean': 0.13418548, 'recall': 0.0, 'global_step': 11}\n",
      "\n",
      "\n",
      "{'accuracy': 0.6256983, 'accuracy_baseline': 0.5865922, 'auc': 0.79395103, 'auc_precision_recall': 0.77203447, 'average_loss': 0.64512944, 'label/mean': 0.41340783, 'loss': 0.64512944, 'precision': 1.0, 'prediction/mean': 0.24542683, 'recall': 0.0945946, 'global_step': 12}\n",
      "\n",
      "\n",
      "{'accuracy': 0.7318436, 'accuracy_baseline': 0.5865922, 'auc': 0.79839116, 'auc_precision_recall': 0.79340523, 'average_loss': 0.58747035, 'label/mean': 0.41340783, 'loss': 0.58747035, 'precision': 0.6911765, 'prediction/mean': 0.4678348, 'recall': 0.6351351, 'global_step': 13}\n",
      "\n",
      "\n",
      "{'accuracy': 0.547486, 'accuracy_baseline': 0.5865922, 'auc': 0.7070785, 'auc_precision_recall': 0.58544743, 'average_loss': 0.7346385, 'label/mean': 0.41340783, 'loss': 0.7346385, 'precision': 0.4755245, 'prediction/mean': 0.64179367, 'recall': 0.9189189, 'global_step': 14}\n",
      "\n",
      "\n",
      "{'accuracy': 0.5083799, 'accuracy_baseline': 0.5865922, 'auc': 0.6868726, 'auc_precision_recall': 0.5540284, 'average_loss': 0.8169995, 'label/mean': 0.41340783, 'loss': 0.8169995, 'precision': 0.45394737, 'prediction/mean': 0.6906, 'recall': 0.9324324, 'global_step': 15}\n",
      "\n",
      "\n",
      "{'accuracy': 0.55307263, 'accuracy_baseline': 0.5865922, 'auc': 0.7072716, 'auc_precision_recall': 0.5920683, 'average_loss': 0.74519825, 'label/mean': 0.41340783, 'loss': 0.74519825, 'precision': 0.47826087, 'prediction/mean': 0.64854, 'recall': 0.8918919, 'global_step': 16}\n",
      "\n",
      "\n",
      "{'accuracy': 0.6927374, 'accuracy_baseline': 0.5865922, 'auc': 0.75450456, 'auc_precision_recall': 0.6740632, 'average_loss': 0.6253748, 'label/mean': 0.41340783, 'loss': 0.6253748, 'precision': 0.60215056, 'prediction/mean': 0.5505862, 'recall': 0.7567568, 'global_step': 17}\n",
      "\n",
      "\n",
      "{'accuracy': 0.7877095, 'accuracy_baseline': 0.5865922, 'auc': 0.81177604, 'auc_precision_recall': 0.8067252, 'average_loss': 0.5490682, 'label/mean': 0.41340783, 'loss': 0.5490682, 'precision': 0.8214286, 'prediction/mean': 0.4027515, 'recall': 0.6216216, 'global_step': 18}\n",
      "\n",
      "\n",
      "{'accuracy': 0.6424581, 'accuracy_baseline': 0.5865922, 'auc': 0.8333976, 'auc_precision_recall': 0.82565904, 'average_loss': 0.5833626, 'label/mean': 0.41340783, 'loss': 0.5833626, 'precision': 0.9166667, 'prediction/mean': 0.26865143, 'recall': 0.14864865, 'global_step': 19}\n",
      "\n",
      "\n",
      "{'accuracy': 0.6312849, 'accuracy_baseline': 0.5865922, 'auc': 0.8267696, 'auc_precision_recall': 0.81760347, 'average_loss': 0.6694139, 'label/mean': 0.41340783, 'loss': 0.6694139, 'precision': 1.0, 'prediction/mean': 0.19146793, 'recall': 0.10810811, 'global_step': 20}\n",
      "\n",
      "\n",
      "{'accuracy': 0.6312849, 'accuracy_baseline': 0.5865922, 'auc': 0.8298584, 'auc_precision_recall': 0.8158144, 'average_loss': 0.70696366, 'label/mean': 0.41340783, 'loss': 0.70696366, 'precision': 1.0, 'prediction/mean': 0.1694963, 'recall': 0.10810811, 'global_step': 21}\n",
      "\n",
      "\n",
      "{'accuracy': 0.6312849, 'accuracy_baseline': 0.5865922, 'auc': 0.8374517, 'auc_precision_recall': 0.8225403, 'average_loss': 0.69083285, 'label/mean': 0.41340783, 'loss': 0.69083285, 'precision': 1.0, 'prediction/mean': 0.17580356, 'recall': 0.10810811, 'global_step': 22}\n",
      "\n",
      "\n",
      "{'accuracy': 0.6424581, 'accuracy_baseline': 0.5865922, 'auc': 0.8404118, 'auc_precision_recall': 0.8293514, 'average_loss': 0.6328931, 'label/mean': 0.41340783, 'loss': 0.6328931, 'precision': 1.0, 'prediction/mean': 0.20897104, 'recall': 0.13513513, 'global_step': 23}\n",
      "\n",
      "\n",
      "{'accuracy': 0.6815643, 'accuracy_baseline': 0.5865922, 'auc': 0.83989704, 'auc_precision_recall': 0.8301159, 'average_loss': 0.56338185, 'label/mean': 0.41340783, 'loss': 0.56338185, 'precision': 0.94736844, 'prediction/mean': 0.27533957, 'recall': 0.24324325, 'global_step': 24}\n",
      "\n",
      "\n",
      "{'accuracy': 0.7765363, 'accuracy_baseline': 0.5865922, 'auc': 0.8243887, 'auc_precision_recall': 0.8200814, 'average_loss': 0.5298493, 'label/mean': 0.41340783, 'loss': 0.5298493, 'precision': 0.8863636, 'prediction/mean': 0.3698456, 'recall': 0.527027, 'global_step': 25}\n",
      "\n",
      "\n",
      "{'accuracy': 0.7318436, 'accuracy_baseline': 0.5865922, 'auc': 0.79259974, 'auc_precision_recall': 0.7676782, 'average_loss': 0.5476156, 'label/mean': 0.41340783, 'loss': 0.5476156, 'precision': 0.6857143, 'prediction/mean': 0.45401722, 'recall': 0.6486486, 'global_step': 26}\n",
      "\n",
      "\n",
      "{'accuracy': 0.67597765, 'accuracy_baseline': 0.5865922, 'auc': 0.7666024, 'auc_precision_recall': 0.7062478, 'average_loss': 0.594885, 'label/mean': 0.41340783, 'loss': 0.594885, 'precision': 0.59302324, 'prediction/mean': 0.522825, 'recall': 0.6891892, 'global_step': 27}\n",
      "\n",
      "\n",
      "{'accuracy': 0.6703911, 'accuracy_baseline': 0.5865922, 'auc': 0.7527027, 'auc_precision_recall': 0.6716395, 'average_loss': 0.6291252, 'label/mean': 0.41340783, 'loss': 0.6291252, 'precision': 0.5862069, 'prediction/mean': 0.55557436, 'recall': 0.6891892, 'global_step': 28}\n",
      "\n",
      "\n",
      "{'accuracy': 0.67597765, 'accuracy_baseline': 0.5865922, 'auc': 0.7574646, 'auc_precision_recall': 0.6837405, 'average_loss': 0.61410785, 'label/mean': 0.41340783, 'loss': 0.61410785, 'precision': 0.59302324, 'prediction/mean': 0.5424413, 'recall': 0.6891892, 'global_step': 29}\n",
      "\n",
      "\n",
      "{'accuracy': 0.68715084, 'accuracy_baseline': 0.5865922, 'auc': 0.786036, 'auc_precision_recall': 0.75450873, 'average_loss': 0.5611458, 'label/mean': 0.41340783, 'loss': 0.5611458, 'precision': 0.60714287, 'prediction/mean': 0.48376864, 'recall': 0.6891892, 'global_step': 30}\n",
      "\n",
      "\n",
      "Model training finished.\n"
     ]
    }
   ],
   "source": [
    "model.train(\n",
    "    data.ts_f,\n",
    "    data.ts_l,\n",
    "    data.vs_f,\n",
    "    data.vs_l\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
