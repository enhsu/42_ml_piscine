{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "from tensorflow.python.framework import ops\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_path = './data/train.csv'\n",
    "test_path = './data/test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class get_data:\n",
    "    def __init__(self, path, is_train=True):\n",
    "        data = pd.read_csv(path)\n",
    "        if is_train:\n",
    "            ts, vs = train_test_split(data, test_size=0.1, random_state=2)\n",
    "            self.ts_f, self.ts_l = self.split_f_l(ts)\n",
    "            self.vs_f, self.vs_l = self.split_f_l(vs)\n",
    "            self.dum_train_val()\n",
    "        else:\n",
    "            self.feature = data.values\n",
    "#         if is_train:\n",
    "#             self.feature = data.drop('label', axis=1)\n",
    "#             self.label = data['label']\n",
    "#         else:\n",
    "#             self.feature = data\n",
    "#         del data\n",
    "        \n",
    "#         self.feature = self.feature.values\n",
    "#         if is_train:\n",
    "#             self.label = pd.get_dummies(self.label).values\n",
    "#             self.ts_f, self.ts_l, self.vs_f, self_vs_l = self.split_t_v()\n",
    "            \n",
    "    def split_f_l(self, data):\n",
    "        f = data.drop('label', axis=1)\n",
    "        l = data['label']\n",
    "        return f, l\n",
    "    \n",
    "    def dum_train_val(self):\n",
    "        self.ts_f = self.ts_f.values\n",
    "        self.ts_l = pd.get_dummies(self.ts_l).values\n",
    "        self.vs_f = self.vs_f.values\n",
    "        self.vs_l = pd.get_dummies(self.vs_l).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class create_model:\n",
    "    def __init__(\n",
    "        self,\n",
    "        ts_f,\n",
    "        ts_l,\n",
    "        vs_f,\n",
    "        vs_l,\n",
    "        learning_rate=1e-3,\n",
    "        epochs=30,\n",
    "        batch_size=64\n",
    "    ):\n",
    "        self.ts_f = ts_f\n",
    "        self.ts_l = ts_l\n",
    "        self.vs_f = vs_f\n",
    "        self.vs_l = vs_l\n",
    "        \n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        # reset computation graph\n",
    "        ops.reset_default_graph()\n",
    "        self.x, self.y, self.prediction_layer = self.buildCNN()\n",
    "        # loss, optim\n",
    "        self.loss, self.optim = self.optimization()\n",
    "        # acc\n",
    "        self.correct_prediction = tf.equal(\n",
    "            tf.argmax(self.prediction_layer, 1),\n",
    "            tf.argmax(self.y, 1)\n",
    "        )\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(self.correct_prediction, 'float'))\n",
    "        \n",
    "        # initialize\n",
    "        self.init = tf.global_variables_initializer()\n",
    "        \n",
    "    def buildCNN(self):\n",
    "        x = tf.placeholder(tf.float32, shape=(None, self.ts_f.shape[1]), name='x')\n",
    "        y = tf.placeholder(tf.float32, shape=(None, self.ts_l.shape[1]), name='y')\n",
    "        \n",
    "        # flatten the input\n",
    "        # 1st layer\n",
    "        m = tf.layers.dense(\n",
    "            x,\n",
    "            units=256,\n",
    "            activation='relu',\n",
    "            kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "            bias_initializer=tf.zeros_initializer()\n",
    "        )\n",
    "        m = tf.layers.dropout(inputs=m, rate=0.4)\n",
    "        \n",
    "        # 2nd layer\n",
    "        m = tf.layers.dense(\n",
    "            m,\n",
    "            units=128,\n",
    "            activation='relu',\n",
    "            kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "            bias_initializer=tf.zeros_initializer()\n",
    "        )\n",
    "        # m = tf.layers.dropout(inputs=m, rate=0.4)\n",
    "        \n",
    "        # 3rd layer\n",
    "        m = tf.layers.dense(\n",
    "            m, units=64,\n",
    "            activation='relu', \n",
    "            kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "            bias_initializer=tf.zeros_initializer()\n",
    "        )\n",
    "        # m = tf.layers.dropout(inputs=m, rate=0.4)\n",
    "        \n",
    "        # 4th layer\n",
    "        m = tf.layers.dense(\n",
    "            m,\n",
    "            units=32,\n",
    "            activation='relu', \n",
    "            kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "            bias_initializer=tf.zeros_initializer()\n",
    "        )\n",
    "        # m = tf.layers.dropout(inputs=m, rate=0.4)\n",
    "        \n",
    "        # 5th layer\n",
    "        m = tf.layers.dense(\n",
    "            m,\n",
    "            units=16,\n",
    "            activation='relu', \n",
    "            kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "            bias_initializer=tf.zeros_initializer()\n",
    "        )\n",
    "        # m = tf.layers.dropout(inputs=m, rate=0.4)\n",
    "        \n",
    "        # output layer\n",
    "        prediction = tf.layers.dense(\n",
    "            m,\n",
    "            units=self.ts_l.shape[1],\n",
    "            name=\"p\", \n",
    "            kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "            bias_initializer=tf.zeros_initializer()\n",
    "        )\n",
    "        \n",
    "        return x, y, prediction\n",
    "    \n",
    "    def optimization(self):\n",
    "        loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=self.prediction_layer, labels=self.y))\n",
    "        optim = tf.train.AdamOptimizer(learning_rate=self.learning_rate).minimize(loss)\n",
    "        return loss, optim\n",
    "    \n",
    "    def train(self):\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(self.init)  #initializes the variables created\n",
    "            for epoch in range(self.epochs):\n",
    "                epoch_cost = 0\n",
    "                epoch_acc = 0\n",
    "                num_minibatches = math.ceil(self.ts_f.shape[0] / self.batch_size)\n",
    "                minibatches = self.random_mini_batches()\n",
    "                for minibatch in minibatches:\n",
    "                    (minibatch_x, minibatch_y) = minibatch\n",
    "                    _, minibatch_cost, p, minibatch_acc  = sess.run([self.optim, self.loss, self.prediction_layer, self.accuracy], feed_dict = {self.x: minibatch_x, self.y: minibatch_y})\n",
    "                    # print(\"pred shape: \", p)\n",
    "                    epoch_cost += minibatch_cost / num_minibatches\n",
    "                    epoch_acc += minibatch_acc / num_minibatches\n",
    "\n",
    "                print(\"cost after epoch %i :  %.3f\" % (epoch + 1, epoch_cost), end=\"\")\n",
    "                print(\"  train accuracy   :  %.3f\" % epoch_acc)\n",
    "                print(\"  cv accuracy   :  %.3f\" % (self.accuracy.eval({self.x: self.vs_f, self.y: self.vs_l})))\n",
    "            print(\"network trained\")\n",
    "            \n",
    "#             predicts = tf.argmax(pred, 1).eval({x:x_test})\n",
    "#             probs = tf.nn.softmax(pred, 1).eval({x: x_test})\n",
    "#             print(\"test shape: \", x_test.shape)\n",
    "#             print(\"predicts shape: \", predicts.shape)\n",
    "#             print(\"predicts val: \", predicts)\n",
    "#             return predicts, probs\n",
    "    \n",
    "    def random_mini_batches(self):\n",
    "        m = self.ts_f.shape[0]\n",
    "        mini_batches = []\n",
    "\n",
    "        #shuffle x and y\n",
    "        permutation = list(np.random.permutation(m))\n",
    "        shuffled_x = self.ts_f[permutation]\n",
    "        shuffled_y = self.ts_l[permutation]\n",
    "\n",
    "        #partition\n",
    "        num_complete_minibatches = math.ceil(m / self.batch_size)\n",
    "        for k in range(0, num_complete_minibatches):\n",
    "            mini_batch_x = shuffled_x[k*self.batch_size : k*self.batch_size + self.batch_size]\n",
    "            mini_batch_y = shuffled_y[k*self.batch_size : k*self.batch_size + self.batch_size]\n",
    "            mini_batch = (mini_batch_x, mini_batch_y)\n",
    "            mini_batches.append(mini_batch)\n",
    "        return mini_batches\n",
    "\n",
    "    def predict(self, test_df):\n",
    "        preds = tf.argmax(self.pred, 1).eval({x: test_df})\n",
    "        probs = tf.nn.softmax(self.pred, 1).eval({x: test_df})\n",
    "        \n",
    "        preds = preds.reshape(-1,1)\n",
    "        preds_df = pd.DataFrame(preds, columns=['Label'])\n",
    "        preds_df['ImageID'] = preds_df.index + 1\n",
    "        self.submission = preds_df[preds_df.columns[::-1]]\n",
    "        \n",
    "    def save_res(self, path):\n",
    "        self.submission.to_csv(path, index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost after epoch 1 :  0.423  train accuracy   :  0.313\n",
      "  cv accuracy   :  0.487\n",
      "cost after epoch 2 :  0.109  train accuracy   :  0.813\n",
      "  cv accuracy   :  0.887\n",
      "cost after epoch 3 :  0.055  train accuracy   :  0.936\n",
      "  cv accuracy   :  0.935\n",
      "cost after epoch 4 :  0.042  train accuracy   :  0.952\n",
      "  cv accuracy   :  0.946\n",
      "cost after epoch 5 :  0.034  train accuracy   :  0.958\n",
      "  cv accuracy   :  0.950\n",
      "cost after epoch 6 :  0.024  train accuracy   :  0.966\n",
      "  cv accuracy   :  0.960\n",
      "cost after epoch 7 :  0.018  train accuracy   :  0.973\n",
      "  cv accuracy   :  0.962\n",
      "cost after epoch 8 :  0.014  train accuracy   :  0.978\n",
      "  cv accuracy   :  0.966\n",
      "cost after epoch 9 :  0.012  train accuracy   :  0.982\n",
      "  cv accuracy   :  0.960\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-409dc3fd117b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-aed4c13859c7>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0mepoch_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                 \u001b[0mnum_minibatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mts_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                 \u001b[0mminibatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_mini_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mminibatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mminibatches\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                     \u001b[0;34m(\u001b[0m\u001b[0mminibatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminibatch_y\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mminibatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-aed4c13859c7>\u001b[0m in \u001b[0;36mrandom_mini_batches\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;31m#shuffle x and y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0mpermutation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m         \u001b[0mshuffled_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mts_f\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0mshuffled_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mts_l\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train = get_data(train_path)\n",
    "# train.ts_l.shape\n",
    "\n",
    "model = create_model(\n",
    "    train.ts_f,\n",
    "    train.ts_l,\n",
    "    train.vs_f,\n",
    "    train.vs_l\n",
    ")\n",
    "\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
