{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow.python.data import Dataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime\n",
    "\n",
    "train_path = './data/train_V2.csv'\n",
    "test_path = './data/test_V2.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class get_data:\n",
    "#     def __init__(self, path, is_train=True):\n",
    "#         if is_train:\n",
    "#             self.df = pd.read_csv(path, nrows=500000)\n",
    "#             self.shuffle_data()\n",
    "#         else:\n",
    "#             self.df = pd.read_csv(path)\n",
    "            \n",
    "#     def shuffle_data(self):\n",
    "#         self.df = self.df.reindex(np.random.permutation(self.df.index))\n",
    "    \n",
    "#     def fillna(self):\n",
    "#         self.df['winPlacePerc'] = self.df\n",
    "\n",
    "class get_data:\n",
    "    def __init__(self, path, is_train=True):\n",
    "        self.is_train = is_train\n",
    "        data = pd.read_csv(path)\n",
    "        if is_train:\n",
    "            data = data.sample(100000)\n",
    "            self.feature = data.drop('winPlacePerc', axis=1)\n",
    "            self.label = data['winPlacePerc']\n",
    "        else:\n",
    "            self.feature = data\n",
    "        del data\n",
    "        \n",
    "        self.deal_feature()\n",
    "        self.x_train = self.feature\n",
    "        if is_train:\n",
    "            self.y_train = self.label\n",
    "#         if is_train:\n",
    "#             self.ts_f, self.ts_l, self.vs_f, self.vs_l = self.split_t_v()\n",
    "        \n",
    "    def deal_feature(self):\n",
    "        self.add_cols()\n",
    "        self.fillna()\n",
    "        self.drop_cols()\n",
    "#         self.featuring()\n",
    "#         self.ohencode()\n",
    "        self.drop_ids()\n",
    "            \n",
    "    def add_cols(self):\n",
    "        self.feature['teamPlayers'] = self.feature['groupId'].map(self.feature['groupId'].value_counts())\n",
    "        self.feature['gamePlayers'] = self.feature['matchId'].map(self.feature['matchId'].value_counts())\n",
    "        self.feature['enemyPlayers'] = self.feature['gamePlayers'] - self.feature['teamPlayers']\n",
    "        self.feature['totalDistance'] = self.feature['rideDistance'] + self.feature['swimDistance'] + self.feature['walkDistance']\n",
    "        self.feature['enemyDamage'] = self.feature['assists'] + self.feature['kills']\n",
    "        \n",
    "        totalKills = self.feature.groupby(['matchId', 'groupId']).agg({'kills': lambda x: x.sum()})\n",
    "        totalKills.rename(columns={'kills': 'squadKills'}, inplace=True)\n",
    "        self.feature = self.feature.join(other=totalKills, on=['matchId', 'groupId'])\n",
    "        \n",
    "        self.feature['medicKits'] = self.feature['heals'] + self.feature['boosts']\n",
    "        self.feature['medicPerKill'] = self.feature['medicKits'] / self.feature['enemyDamage']\n",
    "        self.feature['distancePerHeals'] = self.feature['totalDistance'] / self.feature['heals']\n",
    "        self.feature['headShotKillRatio'] = self.feature['headshotKills'] / self.feature['kills']\n",
    "        self.feature['headshotKillRate'] = self.feature['headshotKills'] / self.feature['kills']\n",
    "        self.feature['killPlaceOverMaxPlace'] = self.feature['killPlace'] / self.feature['maxPlace']\n",
    "        self.feature['kills/walkDistance'] = self.feature['kills'] / self.feature['walkDistance']\n",
    "        self.feature['avgKills'] = self.feature['squadKills'] / self.feature['teamPlayers']\n",
    "        self.feature['damageRatio'] = self.feature['damageDealt'] / self.feature['enemyDamage']\n",
    "        self.feature['distTravelledPerGame'] = self.feature['totalDistance'] / self.feature['matchDuration']\n",
    "        self.feature['killPlacePerc'] = self.feature['killPlace'] / self.feature['gamePlayers']\n",
    "        self.feature['playerSkill'] = self.feature['headshotKills'] + self.feature['roadKills'] + self.feature['assists'] - (5 * self.feature['teamKills'])\n",
    "        self.feature['gamePlacePerc'] = self.feature['killPlace'] / self.feature['maxPlace']\n",
    "    \n",
    "    def fillna(self):\n",
    "        self.feature.fillna(0, inplace=True)\n",
    "        self.feature.replace(np.inf, 0, inplace=True)\n",
    "        if self.is_train:\n",
    "            self.label.fillna(0, inplace=True)\n",
    "            self.label.replace(np.inf, 0, inplace=True)\n",
    "            \n",
    "#     def fillInf(self, val):\n",
    "#         numcols = self.feature.select_dtypes(include='number').columns\n",
    "#         cols = numcols[numcols != 'winPlacePerc']\n",
    "#         self.feature[self.feature == np.Inf] = np.NaN\n",
    "#         self.feature[self.feature == np.NINF] = np.NaN\n",
    "#         for c in cols:\n",
    "#             self.feature[c].fillna(val, inplace=True)\n",
    "        \n",
    "    def ohencode(self):\n",
    "        '''\n",
    "        solo  <-- solo,solo-fpp,normal-solo,normal-solo-fpp\n",
    "        duo   <-- duo,duo-fpp,normal-duo,normal-duo-fpp,crashfpp,crashtpp\n",
    "        squad <-- squad,squad-fpp,normal-squad,normal-squad-fpp,flarefpp,flaretpp\n",
    "        '''\n",
    "        mapper = lambda x: 'solo' if ('solo' in x) else 'duo' if ('duo' in x) or ('crash' in x) else 'squad'\n",
    "        self.feature['matchType'] = self.feature['matchType'].apply(mapper)\n",
    "\n",
    "        self.feature = pd.concat([self.feature, pd.get_dummies(self.feature['matchType'], prefix='matchType')], axis=1)\n",
    "    \n",
    "    def drop_cols(self):\n",
    "        drop_cols = ['killPoints', 'rankPoints', 'winPoints', 'maxPlace']\n",
    "        self.feature.drop(columns=drop_cols, inplace=True)\n",
    "    \n",
    "    def drop_ids(self):\n",
    "        self.feature = self.feature.drop(['Id', 'groupId', 'matchId', 'matchType'], axis=1)\n",
    "    \n",
    "    def featuring(self):\n",
    "        features = list(self.feature.columns)\n",
    "        features.remove(\"Id\")\n",
    "        features.remove(\"matchId\")\n",
    "        features.remove(\"groupId\")\n",
    "        features.remove(\"matchType\")\n",
    "        condition='False'\n",
    "        \n",
    "        if 'winPlacePerc' in self.feature.columns:\n",
    "            y = np.array(self.feature.groupby(['matchId','groupId'])['winPlacePerc'].agg('mean'), dtype=np.float64)\n",
    "            features.remove(\"winPlacePerc\")\n",
    "            condition='True'\n",
    "        \n",
    "        # get group mean feature\n",
    "        agg = self.feature.groupby(['matchId','groupId'])[features].agg('mean')\n",
    "        agg_rank = agg.groupby('matchId')[features].rank(pct=True).reset_index()\n",
    "        df_out = agg.reset_index()[['matchId','groupId']]\n",
    "        df_out = df_out.merge(agg.reset_index(), suffixes=[\"\", \"\"], how='left', on=['matchId', 'groupId'])\n",
    "        df_out = df_out.merge(agg_rank, suffixes=[\"_mean\", \"_mean_rank\"], how='left', on=['matchId', 'groupId'])\n",
    "    \n",
    "        # get group max feature\n",
    "        agg = self.feature.groupby(['matchId','groupId'])[features].agg('max')\n",
    "        agg_rank = agg.groupby('matchId')[features].rank(pct=True).reset_index()\n",
    "        df_out = df_out.merge(agg.reset_index(), suffixes=[\"\", \"\"], how='left', on=['matchId', 'groupId'])\n",
    "        df_out = df_out.merge(agg_rank, suffixes=[\"_max\", \"_max_rank\"], how='left', on=['matchId', 'groupId'])\n",
    "        \n",
    "        # get group min feature\n",
    "        agg = self.feature.groupby(['matchId','groupId'])[features].agg('min')\n",
    "        agg_rank = agg.groupby('matchId')[features].rank(pct=True).reset_index()\n",
    "        df_out = df_out.merge(agg.reset_index(), suffixes=[\"\", \"\"], how='left', on=['matchId', 'groupId'])\n",
    "        df_out = df_out.merge(agg_rank, suffixes=[\"_min\", \"_min_rank\"], how='left', on=['matchId', 'groupId'])\n",
    "        \n",
    "        # get match mean feature\n",
    "        agg = self.feature.groupby(['matchId'])[features].agg('mean').reset_index()\n",
    "        df_out = df_out.merge(agg, suffixes=[\"\", \"_match_mean\"], how='left', on=['matchId'])\n",
    "        df_id=df_out[[\"matchId\", \"groupId\"]].copy()\n",
    "        df_out.drop([\"matchId\", \"groupId\"], axis=1, inplace=True)\n",
    "\n",
    "        del agg, agg_rank\n",
    "        gc.collect()\n",
    "        if condition == 'True':\n",
    "            return df_out,pd.DataFrame(y),df_id\n",
    "        else:\n",
    "            return df_out,df_id\n",
    "        \n",
    "    def split_t_v(self):\n",
    "        self.ts_f, self.vs_f, self.ts_l, self.vs_l = \\\n",
    "        train_test_split(\n",
    "            self.feature,\n",
    "            self.label,\n",
    "            test_size=0.2,\n",
    "            random_state=42\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class create_model:\n",
    "    def __init__(\n",
    "        self,\n",
    "        train_df,\n",
    "        periods = 10,\n",
    "        steps = 10000,\n",
    "        save_model = True,\n",
    "        save_model_name = 'train_v0'\n",
    "    ):\n",
    "        self.train = train_df\n",
    "        self.periods = periods\n",
    "        self.steps = steps\n",
    "        \n",
    "        self.save_model = save_model\n",
    "        self.save_model_path = './model/estimator/' + save_model_name\n",
    "        \n",
    "        self.create_feature_columns()\n",
    "#         self.create_optimizer()\n",
    "        \n",
    "        model_arg = dict(\n",
    "            feature_columns = self.featureCols,\n",
    "            hidden_units = [1024, 128, 32],\n",
    "            optimizer = 'Adam'#self.optimizer\n",
    "        )\n",
    "        if self.save_model:\n",
    "            model_arg['model_dir'] = self.save_model_path\n",
    "        self.model = tf.estimator.DNNRegressor(**model_arg)\n",
    "        print('create model!')\n",
    "    \n",
    "    def create_feature_columns(self):\n",
    "#         featureColumns = []\n",
    "#         featureColumns.append(tf.feature_column.numeric_column('boosts'))\n",
    "#         featureColumns.append(tf.feature_column.numeric_column('headshotKills'))\n",
    "#         featureColumns.append(tf.feature_column.numeric_column('heals'))\n",
    "#         featureColumns.append(tf.feature_column.numeric_column('kills'))\n",
    "#         featureColumns.append(tf.feature_column.numeric_column('walkDistance'))\n",
    "#         featureColumns.append(tf.feature_column.numeric_column('weaponsAcquired'))\n",
    "#         self.featureCols = featureColumns\n",
    "        self.featureCols = set([tf.feature_column.numeric_column(my_feature) for my_feature in self.train])\n",
    "    \n",
    "    def create_optimizer(self):\n",
    "#         self.optimizer = tf.train.ProximalAdagradOptimizer(\n",
    "#             learning_rate = 0.003,\n",
    "#             l1_regularization_strength = 0.001\n",
    "#         )\n",
    "        self.optimizer = lambda: tf.contrib.optimizer_v2.AdamOptimizer(\n",
    "            learning_rate=tf.exponential_decay(\n",
    "                learning_rate=0.01,\n",
    "                global_step=tf.get_global_step(),\n",
    "                decay_steps=10000,\n",
    "                decay_rate=0.96\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def training(\n",
    "        self,\n",
    "        ts_f,\n",
    "        ts_l,\n",
    "        vs_f,\n",
    "        vs_l\n",
    "    ):\n",
    "        self.ts_f = ts_f\n",
    "        self.ts_l = ts_l\n",
    "        self.vs_f = vs_f\n",
    "        self.vs_l = vs_l\n",
    "        self.create_input_fn()\n",
    "        \n",
    "        print('training start.')\n",
    "        step_period = self.steps / self.periods\n",
    "        for period in range(self.periods):\n",
    "            print('start eval')\n",
    "            evaluate = self.model.evaluate(input_fn=self.eval_fn, steps=step_period)\n",
    "            print('start training')\n",
    "            training = self.model.train(input_fn=self.train_fn, steps=step_period)\n",
    "            print('period: ', period)\n",
    "        evaluate = self.model.evaluate(input_fn=self.eval_fn, steps=step_period)\n",
    "        print('training done.')\n",
    "            \n",
    "    def create_input_fn(self):\n",
    "        self.create_train_fn()\n",
    "        self.create_eval_fn()\n",
    "        \n",
    "    def create_train_fn(self):\n",
    "#         self.train_fn = tf.estimator.inputs.pandas_input_fn(\n",
    "#             x = self.ts_f,\n",
    "#             y = self.ts_l,\n",
    "#             batch_size = 30,\n",
    "#             num_epochs = None,\n",
    "#             shuffle = True,\n",
    "#         )\n",
    "        self.train_fn = lambda: self.my_input_fn(self.ts_f, self.ts_l, batch_size=30, shuffle=True)\n",
    "        \n",
    "    def create_eval_fn(self):\n",
    "#         self.eval_fn = tf.estimator.inputs.pandas_input_fn(\n",
    "#             x = self.vs_f,\n",
    "#             y = self.vs_l,\n",
    "#             batch_size = 1,\n",
    "#             num_epochs = 1,\n",
    "#             shuffle = True,\n",
    "#         )\n",
    "        self.eval_fn = lambda: self.my_input_fn(self.vs_f, self.vs_l, batch_size=1, num_epochs=1)\n",
    "        \n",
    "#     def my_input_fn(self, train_X, train_y, batch_size=64, shuffle=False):\n",
    "#         dataset = tf.data.Dataset.from_tensor_slices((train_X, train_y))\n",
    "\n",
    "#         dataset = dataset.map(lambda x,y: self.preprocess_data(x, y))\n",
    "\n",
    "#         if shuffle:\n",
    "#             dataset = dataset.shuffle(buffer_size=128)\n",
    "\n",
    "#         dataset = dataset.batch(batch_size)\n",
    "\n",
    "#         itr = dataset.make_one_shot_iterator()\n",
    "#         features, target = itr.get_next()\n",
    "\n",
    "#         return features, target\n",
    "    def my_input_fn(self, features, targets, batch_size=1, shuffle=True, num_epochs=None):\n",
    "        # Convert pandas data into a dict of np arrays.\n",
    "        features = {key:np.array(value) for key,value in dict(features).items()}\n",
    "        # Construct a dataset, and configure batching/repeating.\n",
    "        ds = Dataset.from_tensor_slices((features,targets)) # warning: 2GB limit\n",
    "        ds = ds.batch(batch_size).repeat(num_epochs)\n",
    "        # Shuffle the data, if specified.\n",
    "        if shuffle:\n",
    "            ds = ds.shuffle(42)\n",
    "        # Return the next batch of data.\n",
    "        features, labels = ds.make_one_shot_iterator().get_next()\n",
    "        return features, labels\n",
    "    \n",
    "    def preprocess_data(self, x, y):\n",
    "        labels = tf.cast(y, tf.int32)\n",
    "        input_data = tf.cast(x, tf.float32)\n",
    "        return (dict({'image': input_data}), labels)\n",
    "\n",
    "    def predict(self, test_df):\n",
    "        self.test_df = test_df\n",
    "        self.create_predict_fn()\n",
    "        prediction = self.model.predict(input_fn=self.predict_fn)\n",
    "        prediction = [item['predictions'][0] for item in prediction]\n",
    "        \n",
    "        self.result = pd.DataFrame(\n",
    "            [(Id, pred) for Id, pred in zip(testData['Id'], prediction)],\n",
    "            columns = ['Id', 'winPlacePerc']\n",
    "        )\n",
    "        \n",
    "    def create_predict_fn(self):\n",
    "        self.predict_fn = tf.estimator.inputs.pandas_input_fn(\n",
    "            x = self.test_df,\n",
    "            y = None,\n",
    "            batch_size = 1,\n",
    "            num_epochs = 1,\n",
    "            shuffle = False,\n",
    "        )\n",
    "    \n",
    "    def save_result(self, path='./result/estimator/submission.csv'):\n",
    "        self.result.to_csv(path, index=False)\n",
    "        \n",
    "    def test(self):\n",
    "        print('model work!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>assists</th>\n",
       "      <th>boosts</th>\n",
       "      <th>damageDealt</th>\n",
       "      <th>DBNOs</th>\n",
       "      <th>headshotKills</th>\n",
       "      <th>heals</th>\n",
       "      <th>killPlace</th>\n",
       "      <th>kills</th>\n",
       "      <th>killStreaks</th>\n",
       "      <th>longestKill</th>\n",
       "      <th>...</th>\n",
       "      <th>headShotKillRatio</th>\n",
       "      <th>headshotKillRate</th>\n",
       "      <th>killPlaceOverMaxPlace</th>\n",
       "      <th>kills/walkDistance</th>\n",
       "      <th>avgKills</th>\n",
       "      <th>damageRatio</th>\n",
       "      <th>distTravelledPerGame</th>\n",
       "      <th>killPlacePerc</th>\n",
       "      <th>playerSkill</th>\n",
       "      <th>gamePlacePerc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2570433</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.869565</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028809</td>\n",
       "      <td>17.200000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.869565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1413687</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>319.40</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>45.150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>106.466667</td>\n",
       "      <td>2.411576</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.384615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3792070</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>131.70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.801</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.000318</td>\n",
       "      <td>1.0</td>\n",
       "      <td>131.700000</td>\n",
       "      <td>2.281363</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159183</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22.96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.326531</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.109136</td>\n",
       "      <td>21.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>1.326531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910313</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.969072</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.969072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         assists  boosts  damageDealt  DBNOs  headshotKills  heals  killPlace  \\\n",
       "2570433        0       0         0.00      0              0      0         86   \n",
       "1413687        0       3       319.40      3              0      3         10   \n",
       "3792070        0       7       131.70      0              0      4         25   \n",
       "159183         0       1        22.96      0              0      1         65   \n",
       "910313         0       0         0.00      0              0      0         94   \n",
       "\n",
       "         kills  killStreaks  longestKill  ...  headShotKillRatio  \\\n",
       "2570433      0            0        0.000  ...                0.0   \n",
       "1413687      3            2       45.150  ...                0.0   \n",
       "3792070      1            1        8.801  ...                0.0   \n",
       "159183       0            0        0.000  ...                0.0   \n",
       "910313       0            0        0.000  ...                0.0   \n",
       "\n",
       "         headshotKillRate  killPlaceOverMaxPlace  kills/walkDistance  \\\n",
       "2570433               0.0               1.869565            0.000000   \n",
       "1413687               0.0               0.384615            0.001000   \n",
       "3792070               0.0               0.833333            0.000318   \n",
       "159183                0.0               1.326531            0.000000   \n",
       "910313                0.0               0.969072            0.000000   \n",
       "\n",
       "         avgKills  damageRatio  distTravelledPerGame  killPlacePerc  \\\n",
       "2570433       0.0     0.000000              0.028809      17.200000   \n",
       "1413687       3.0   106.466667              2.411576       2.000000   \n",
       "3792070       1.0   131.700000              2.281363      12.500000   \n",
       "159183        0.0     0.000000              0.109136      21.666667   \n",
       "910313        0.0     0.000000              0.000000      18.800000   \n",
       "\n",
       "         playerSkill  gamePlacePerc  \n",
       "2570433            0       1.869565  \n",
       "1413687            0       0.384615  \n",
       "3792070            0       0.833333  \n",
       "159183             0       1.326531  \n",
       "910313             0       0.969072  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data= get_data(train_path)\n",
    "data.feature.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create model!\n"
     ]
    }
   ],
   "source": [
    "model = create_model(data.feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training start.\n",
      "start eval\n",
      "start training\n",
      "period:  0\n",
      "start eval\n",
      "start training\n",
      "period:  1\n",
      "start eval\n",
      "start training\n",
      "period:  2\n",
      "start eval\n",
      "start training\n",
      "period:  3\n",
      "start eval\n",
      "start training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0323 19:56:45.605542 140038697522944 deprecation.py:323] From /home/g42chsu/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py:965: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "period:  4\n",
      "start eval\n",
      "start training\n",
      "period:  5\n",
      "start eval\n",
      "start training\n",
      "period:  6\n",
      "start eval\n",
      "start training\n",
      "period:  7\n",
      "start eval\n",
      "start training\n",
      "period:  8\n",
      "start eval\n",
      "start training\n",
      "period:  9\n",
      "training done.\n"
     ]
    }
   ],
   "source": [
    "data.split_t_v()\n",
    "model.training(\n",
    "    data.ts_f,\n",
    "    data.ts_l,\n",
    "    data.vs_f,\n",
    "    data.vs_l\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
