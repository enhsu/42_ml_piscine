{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "train_path = './data/train_V2.csv'\n",
    "test_path = './data/test_V2.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class get_data:\n",
    "    def __init__(self, path, is_train=True):\n",
    "        self.is_train = is_train\n",
    "        data = pd.read_csv(path)\n",
    "        \n",
    "        if is_train:\n",
    "            self.feature = data.drop('winPlacePerc', axis=1)\n",
    "            self.label = data['winPlacePerc']\n",
    "        else:\n",
    "            self.feature = data\n",
    "        del data\n",
    "        \n",
    "        self.deal_feature()\n",
    "        self.x_train = self.feature\n",
    "        if is_train:\n",
    "            self.y_train = self.label\n",
    "            self.ts_f, self.ts_l, self.vs_f, self.vs_l = self.split_t_v()\n",
    "#         if is_train:\n",
    "#             self.ts_f, self.ts_l, self.vs_f, self.vs_l = self.split_t_v()\n",
    "        \n",
    "    def deal_feature(self):\n",
    "        self.add_cols()\n",
    "        self.fillna()\n",
    "        self.drop_cols()\n",
    "#         self.featuring()\n",
    "#         self.ohencode()\n",
    "        self.drop_ids()\n",
    "            \n",
    "    def add_cols(self):\n",
    "        self.feature['teamPlayers'] = self.feature['groupId'].map(self.feature['groupId'].value_counts())\n",
    "        self.feature['gamePlayers'] = self.feature['matchId'].map(self.feature['matchId'].value_counts())\n",
    "        self.feature['enemyPlayers'] = self.feature['gamePlayers'] - self.feature['teamPlayers']\n",
    "        self.feature['totalDistance'] = self.feature['rideDistance'] + self.feature['swimDistance'] + self.feature['walkDistance']\n",
    "        self.feature['enemyDamage'] = self.feature['assists'] + self.feature['kills']\n",
    "        \n",
    "        totalKills = self.feature.groupby(['matchId', 'groupId']).agg({'kills': lambda x: x.sum()})\n",
    "        totalKills.rename(columns={'kills': 'squadKills'}, inplace=True)\n",
    "        self.feature = self.feature.join(other=totalKills, on=['matchId', 'groupId'])\n",
    "        \n",
    "        self.feature['medicKits'] = self.feature['heals'] + self.feature['boosts']\n",
    "        self.feature['medicPerKill'] = self.feature['medicKits'] / self.feature['enemyDamage']\n",
    "        self.feature['distancePerHeals'] = self.feature['totalDistance'] / self.feature['heals']\n",
    "        self.feature['headShotKillRatio'] = self.feature['headshotKills'] / self.feature['kills']\n",
    "        self.feature['headshotKillRate'] = self.feature['headshotKills'] / self.feature['kills']\n",
    "        self.feature['killPlaceOverMaxPlace'] = self.feature['killPlace'] / self.feature['maxPlace']\n",
    "        self.feature['kills/walkDistance'] = self.feature['kills'] / self.feature['walkDistance']\n",
    "        self.feature['avgKills'] = self.feature['squadKills'] / self.feature['teamPlayers']\n",
    "        self.feature['damageRatio'] = self.feature['damageDealt'] / self.feature['enemyDamage']\n",
    "        self.feature['distTravelledPerGame'] = self.feature['totalDistance'] / self.feature['matchDuration']\n",
    "        self.feature['killPlacePerc'] = self.feature['killPlace'] / self.feature['gamePlayers']\n",
    "        self.feature['playerSkill'] = self.feature['headshotKills'] + self.feature['roadKills'] + self.feature['assists'] - (5 * self.feature['teamKills'])\n",
    "        self.feature['gamePlacePerc'] = self.feature['killPlace'] / self.feature['maxPlace']\n",
    "    \n",
    "    def fillna(self):\n",
    "        self.feature.fillna(0, inplace=True)\n",
    "        self.feature.replace(np.inf, 0, inplace=True)\n",
    "        if self.is_train:\n",
    "            self.label.fillna(0, inplace=True)\n",
    "            self.label.replace(np.inf, 0, inplace=True)\n",
    "            \n",
    "#     def fillInf(self, val):\n",
    "#         numcols = self.feature.select_dtypes(include='number').columns\n",
    "#         cols = numcols[numcols != 'winPlacePerc']\n",
    "#         self.feature[self.feature == np.Inf] = np.NaN\n",
    "#         self.feature[self.feature == np.NINF] = np.NaN\n",
    "#         for c in cols:\n",
    "#             self.feature[c].fillna(val, inplace=True)\n",
    "        \n",
    "    def ohencode(self):\n",
    "        '''\n",
    "        solo  <-- solo,solo-fpp,normal-solo,normal-solo-fpp\n",
    "        duo   <-- duo,duo-fpp,normal-duo,normal-duo-fpp,crashfpp,crashtpp\n",
    "        squad <-- squad,squad-fpp,normal-squad,normal-squad-fpp,flarefpp,flaretpp\n",
    "        '''\n",
    "        mapper = lambda x: 'solo' if ('solo' in x) else 'duo' if ('duo' in x) or ('crash' in x) else 'squad'\n",
    "        self.feature['matchType'] = self.feature['matchType'].apply(mapper)\n",
    "\n",
    "        self.feature = pd.concat([self.feature, pd.get_dummies(self.feature['matchType'], prefix='matchType')], axis=1)\n",
    "    \n",
    "    def drop_cols(self):\n",
    "        drop_cols = ['killPoints', 'rankPoints', 'winPoints', 'maxPlace']\n",
    "        self.feature.drop(columns=drop_cols, inplace=True)\n",
    "    \n",
    "    def drop_ids(self):\n",
    "        self.feature = self.feature.drop(['Id', 'groupId', 'matchId', 'matchType'], axis=1)\n",
    "    \n",
    "    def featuring(self):\n",
    "        features = list(self.feature.columns)\n",
    "        features.remove(\"Id\")\n",
    "        features.remove(\"matchId\")\n",
    "        features.remove(\"groupId\")\n",
    "        features.remove(\"matchType\")\n",
    "        condition='False'\n",
    "        \n",
    "        if 'winPlacePerc' in self.feature.columns:\n",
    "            y = np.array(self.feature.groupby(['matchId','groupId'])['winPlacePerc'].agg('mean'), dtype=np.float64)\n",
    "            features.remove(\"winPlacePerc\")\n",
    "            condition='True'\n",
    "        \n",
    "        # get group mean feature\n",
    "        agg = self.feature.groupby(['matchId','groupId'])[features].agg('mean')\n",
    "        agg_rank = agg.groupby('matchId')[features].rank(pct=True).reset_index()\n",
    "        df_out = agg.reset_index()[['matchId','groupId']]\n",
    "        df_out = df_out.merge(agg.reset_index(), suffixes=[\"\", \"\"], how='left', on=['matchId', 'groupId'])\n",
    "        df_out = df_out.merge(agg_rank, suffixes=[\"_mean\", \"_mean_rank\"], how='left', on=['matchId', 'groupId'])\n",
    "    \n",
    "        # get group max feature\n",
    "        agg = self.feature.groupby(['matchId','groupId'])[features].agg('max')\n",
    "        agg_rank = agg.groupby('matchId')[features].rank(pct=True).reset_index()\n",
    "        df_out = df_out.merge(agg.reset_index(), suffixes=[\"\", \"\"], how='left', on=['matchId', 'groupId'])\n",
    "        df_out = df_out.merge(agg_rank, suffixes=[\"_max\", \"_max_rank\"], how='left', on=['matchId', 'groupId'])\n",
    "        \n",
    "        # get group min feature\n",
    "        agg = self.feature.groupby(['matchId','groupId'])[features].agg('min')\n",
    "        agg_rank = agg.groupby('matchId')[features].rank(pct=True).reset_index()\n",
    "        df_out = df_out.merge(agg.reset_index(), suffixes=[\"\", \"\"], how='left', on=['matchId', 'groupId'])\n",
    "        df_out = df_out.merge(agg_rank, suffixes=[\"_min\", \"_min_rank\"], how='left', on=['matchId', 'groupId'])\n",
    "        \n",
    "        # get match mean feature\n",
    "        agg = self.feature.groupby(['matchId'])[features].agg('mean').reset_index()\n",
    "        df_out = df_out.merge(agg, suffixes=[\"\", \"_match_mean\"], how='left', on=['matchId'])\n",
    "        df_id=df_out[[\"matchId\", \"groupId\"]].copy()\n",
    "        df_out.drop([\"matchId\", \"groupId\"], axis=1, inplace=True)\n",
    "\n",
    "        del agg, agg_rank\n",
    "        gc.collect()\n",
    "        if condition == 'True':\n",
    "            return df_out,pd.DataFrame(y),df_id\n",
    "        else:\n",
    "            return df_out,df_id\n",
    "        \n",
    "    def split_t_v(self):\n",
    "        ts_f, vs_f, ts_l, vs_l = \\\n",
    "        train_test_split(\n",
    "            self.feature,\n",
    "            self.label,\n",
    "            test_size=0.1,\n",
    "            random_state=2\n",
    "        )\n",
    "        return ts_f, ts_l, vs_f, vs_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class create_model:\n",
    "    def __init__(\n",
    "        self,\n",
    "        feature_df,\n",
    "    ):\n",
    "        self.feature_df = feature_df\n",
    "        \n",
    "        self.create_feature_columns()\n",
    "\n",
    "        self.model = tf.estimator.DNNRegressor(\n",
    "            feature_columns=self.feature_columns,\n",
    "            hidden_units=[1024, 128, 32],\n",
    "            optimizer='Adam'\n",
    "        )\n",
    "    \n",
    "    def create_feature_columns(self):\n",
    "        self.feature_columns = set([tf.feature_column.numeric_column(my_feature) for my_feature in self.feature_df])\n",
    "        \n",
    "    def training(\n",
    "        self,\n",
    "        ts_f,\n",
    "        ts_l,\n",
    "        vs_f,\n",
    "        vs_l\n",
    "    ):\n",
    "        self.ts_f = ts_f\n",
    "        self.ts_l = ts_l\n",
    "        self.vs_f = vs_f\n",
    "        self.vs_l = vs_l\n",
    "        self.create_input_fn()\n",
    "        \n",
    "        self.model.train(input_fn=self.train_input_fn)\n",
    "        \n",
    "    def create_input_fn(self):\n",
    "        self.train_input_fn = lambda: self.my_input_fn()\n",
    "        \n",
    "    def my_input_fn(self, features, targets, batch_size=1, shuffle=True, num_epochs=None):\n",
    "        # Convert pandas data into a dict of np arrays.\n",
    "        features = {key:np.array(value) for key,value in dict(features).items()}\n",
    "        # Construct a dataset, and configure batching/repeating.\n",
    "        ds = Dataset.from_tensor_slices((features,targets)) # warning: 2GB limit\n",
    "        ds = ds.batch(batch_size).repeat(num_epochs)\n",
    "        # Shuffle the data, if specified.\n",
    "        if shuffle:\n",
    "            ds = ds.shuffle(42)\n",
    "        # Return the next batch of data.\n",
    "        features, labels = ds.make_one_shot_iterator().get_next()\n",
    "        return features, labels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
